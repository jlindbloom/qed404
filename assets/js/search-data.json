{
  
    
        "post0": {
            "title": "Accelerated ODE Inference with PyDEns and PyMC3",
            "content": "!!! This is a work-in-progress !!! . Traditional Approaches . As a newcommer to the PyMC3 community about a year ago, one of the things I was most excited to learn about was using PyMC3 to perform Bayesian inference for systems of ordinary differential equations (ODEs). In order to take advantage of the efficiency of the NUTS sampler you must be able to provide gradients of the model with respect to each of the model parameters, which can be tricky for ODEs. In my experiences, ignoring the case in which you happen to know the analytic solution there seems to be three approaches to achieving this: . Write an ODE solver entirely in Theano which automatically gives you ability to get gradients via autodiff. This might seem like the easiest way to get the gradients, but you lose the confidence provided by well-tested solvers and it is hard to control the errors in the calculated gradients. | Use an ODE solver coupled with the adjoint method to get the gradients by solving an associated system of ODEs. This is what is done in the package sunode. | Use an ODE solver coupled with local sensitivity analysis to get the gradients by solving an augmented system of ODEs. This is the approach taken in the PyMC3 example on the Lotka-Volterra model with manual gradients. | However, you may have noticed that sometimes these methods can be slow. Let&#39;s take a look at what might cause this. Suppose we are given some parametric ODE system $$ frac{d mathbf{x}}{dt} = f( mathbf{x}, t; theta) $$ with an initial condition $ mathbf{x}_0$ and would like to know both $ mathbf{x}(T)$ and $ frac{ partial mathbf{x}(T)}{ partial theta}$ for some later time $T &gt; 0$. Traditional methods for approximating $ mathbf{x}(T)$ boil down to computing a sequence of points $ { (t_j, mathbf{x}^{j}) }_{j=0}^{M}$ with the goal being that $ mathbf{x}^M approx mathbf{x}(T)$. We might compute this sequence using the Euler method or better yet a Runge-Kutta method. If we want to increase the accuracy of our approximation $ mathbf{x}^M approx mathbf{x}(T)$ we can decrease the timestep of our method which consequently lengthens the sequence of intermediary points we must compute. If all we care about is getting $ mathbf{x}^M$ correct and won&#39;t use the other points $ { mathbf{x}^{j} }_{j=0}^{M-1}$ for anything, we end up computing an awfully large amount of intermediary points we don&#39;t actually care about. Now you might point out that in practice we often get a whole time-series of observations and that actually we will be using many of these intermediary points. OK, fine. But what if our desired numerical accuracy of our solver requires a timestep that makes our observations sparse in time when compared to the granularity of our approximating sequence? This is effectively the same dilemma as before &mdash; we approximate the solution of the ODE at a ton of times that we don&#39;t actually care about it. Inference with ODEs using these methods can be slow since each step of MCMC must re-calculate these lengthy sequences of points for a different set of parameters $ theta$. If we want to speed up ODE inference, it seems like our time would be well-spent trying to avoid the calculation of these sequences at each step. The goal of this post is to introduce a new and exciting alternative to achieve this! . An Outline of the Neural Network Approach . The neural network approach to inference for ODEs involves an expensive offline step that then permits lightning-fast online inference. By offline, I mean that we can offload the computational expense associated with approximating ODE solutions during inference by pre-computing entire families of solutions in advance. But rather than building up a database of ODE solutions calculated from some traditional solver and then querying/interpolating from that, we instead use a neural network to encode this information. Miraculously, training this neural network requires no reference solutions to learn from. This offline step might end up being more costly on net for a given tolerance than if we were to just approximate the ODE solution with some traditional solver, but the point is that this approach allows us to pay this cost upfront instead of gradually over the course of an inference algorithm like MCMC. This approach will also allow us to circumvent the aforementioned burden of having to compute solutions and gradients for intermediary time points between our observations each time we query a solution of the ODE. An extra benefit is that if we want to fit the same ODE to many different sets of data, we can just save and reload our neural network instead of incurring the cost of the expensive offline step each time. . Thinking Differently About Differential Equations . A concept we need to introduce before we dive in is the flow map associated to an autonomous ODE. Suppose that we know we start at $ mathbf{x}_0 in mathbb{R}^d$ and want to know where in the phase space we&#39;ll be at time $t = tau$. The flow map $ Phi_ tau : mathbb{R}^d to mathbb{R}^d$ is the function that takes us from $ mathbb{x}_0$ directly to $ mathbb{x}( tau)$, as well as from any other possible initial condition $ mathbb{x}_0&#39;$ we could&#39;ve chosen to where it would be at time $t = tau$. In other words, $$ Phi_ tau( mathbb{x}_0) = mathbb{x}( tau) $$ where $ mathbb{x}(t)$ is the solution to the initial value problem $$ begin{align} cfrac{d mathbb{x}}{dt} &amp;= f( mathbb{x}; theta) &amp; text{for $t in [0, tau]$} mathbb{x}(0) &amp;= mathbb{x}_0 end{align} $$ If we knew the flow map $ Phi_ tau$ for any $ mathbb{x}_0 in mathbb{R}^d$ and $ tau &gt; 0$ then we wouldn&#39;t have to bother with calculating an approximating sequence with a traditional solver in order to approximate $ mathbb{x}(T)$ &mdash; we could just evaluate $ Phi_T( mathbb{x}_0) = mathbb{x}(T)$. If we also knew $ frac{ partial Phi_ tau}{ partial theta}$, the gradient of the flow map with respect to the ODE parameters, we would have all of the requisite information we need to then proceed with using a gradient-based sampler like NUTS. This is all much easier said than done, but we will proceed with trying to approximate $ Phi_ tau$ and $ frac{ partial Phi_ tau}{ partial theta}$. . Using Neural Networks to Solve ODEs . If you&#39;re reading this post and don&#39;t know much about neural networks, don&#39;t worry &mdash; I&#39;m no expert either. In this post, a &quot;neural network&quot; simply refers to some function $F_{ mathcal{ eta}} : mathbb{R}^{d_1} to mathbb{R}^{d_2}$ where $ eta$ represents some set of trainable parameters (treat these completely separate from our model parameters $ theta$). By &quot;trainable&quot; I mean that we can tweak $ eta$ in order to get $F_ eta$ to &quot;agree&quot; with some other function $G: mathbb{R}^d to mathbb{R}^d$, and by &quot;agree&quot; I mean that given some set of points $ P subset mathbb{R}^{d_1} $ we can tweak $ eta$ to get $F_ eta( mathbb{x}) approx G( mathbb{x})$ for $ mathbb{x} in P$. Recall that the flow map $ Phi_ tau$ we introduced was a function $ Phi_ tau: mathbb{R}^d to mathbb{R}^d$. Let&#39;s define a new function $ Phi$ by moving $ tau$ out of the subscript such that $ Phi( mathbb{x}_0, tau) = Phi_ tau( mathbb{x}_0)$. Now we have a function $ Phi: mathbb{R}^{d+1} to mathbb{R}^d$. Earlier we restricted our discussion to just autonomous ODEs, but what we&#39;re about to do applies to non-autonomous ODEs as well. What if we took $d_1 = d+1$, $d_2=d$, and then tried to train $F_ eta$ to agree with $ Phi$? . Enter PyDEns, a Python package for solving ODEs (and PDEs) with neural networks that does just this. I will not go into the specifics here of how to use PyDEns or the theory of what is going on under the hood since the PyDEns developers provide an excellent series of tutorial notebooks here. Perhaps it&#39;s best to start with an example of PyDEns in action. $$ cfrac{dx}{dt} = cos(t) $$ with some initial condition $x(0) = x_0$, for which we know that the analytic solution is $$ x(t) = sin(t) + x_0. $$ Ignoring the specifics of what&#39;s going on down below, let&#39;s fix $x_0 = 0$ and use PyDEns to train a neural network that solves this ODE. . import os import sys import warnings warnings.filterwarnings(&#39;ignore&#39;) from tensorflow import logging logging.set_verbosity(logging.ERROR) os.environ[&#39;TF_CPP_MIN_LOG_LEVEL&#39;] = &#39;2&#39; from tqdm import tqdm_notebook import tensorflow as tf from pydens import Solver, NumpySampler, cart_prod, add_tokens from pydens import plot_loss, plot_pair_1d, plot_2d, plot_sections_2d, plot_sections_3d import numpy as np import matplotlib.pyplot as plt add_tokens() . . ode = { &#39;n_dims&#39;: 1, &#39;form&#39;: lambda u, t : D(u, t) - cos(t), &#39;initial_condition&#39;: 0.0, } config = { &#39;pde&#39;: ode, } dg = Solver(config) sampler = NumpySampler(&#39;uniform&#39;, dim=1, low=0.0, high=10.0) dg.fit(batch_size=50, sampler=sampler, n_iters=100000, bar=&quot;notebook&quot;) . That looks like it did something exciting! Let&#39;s look at the solution that our neural network predicts. . t = np.linspace(0, 10, 100) # Get the NN solution t_reshaped = t[:, None] nn_sol = dg.solve(t_reshaped)[:,0] # Get the analytic solution analytic_sol = np.sin(t) # Get the error error = np.abs(analytic_sol - nn_sol) # Plot fig, axs = plt.subplots(1, 2, figsize=(13,5)) # The solutions axs[0].plot(t, nn_sol, label=&quot;Neural Network&quot;) axs[0].plot(t, analytic_sol, label=&quot;Analytic&quot;, linestyle=&quot;--&quot;) axs[0].set_xlabel(r&quot;$t$&quot;) axs[0].set_ylabel(r&quot;$x(t)$&quot;) axs[0].set_title(&quot;Solution&quot;) axs[0].legend() # The error axs[1].plot(t, error) axs[1].set_xlabel(r&quot;$t$&quot;) axs[1].set_ylabel(&quot;Absolute Error&quot;) axs[1].set_title(&quot;Solution Error&quot;) plt.show() . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-11T11:53:02.846401 image/svg+xml Matplotlib v3.3.4, https://matplotlib.org/ That looks pretty accurate! Perhaps you&#39;re unimpressed since all we did was learn a simple sine curve, so let&#39;s try to learn to solve an entire parametric family of ODEs by adding a parameter to this ODE $$ cfrac{dx}{dt} = alpha cos(t) $$ with fixed $x_0 = 0$. The analytic solution for this ODE is just $$ x(t) = alpha sin(t) + x_0. $$ One feature of this approach is that we must specify the range of values we would like to train the parameters over. In this example, we&#39;ll train the neural network to solve the ODE for $ alpha in [-3, 3]$. . ode = { &#39;n_dims&#39;: 1, &#39;form&#39;: lambda u, t, alpha : D(u, t) - P(alpha)*cos(t), &#39;initial_condition&#39;: 0.0, } config = { &#39;pde&#39;: ode, &#39;track&#39;: {&#39;dxdalpha&#39;: lambda u, t, alpha: D(u, alpha)} } dg = Solver(config) sampler = NumpySampler(&#39;uniform&#39;, low=0.0, high=10.0) &amp; NumpySampler(&#39;uniform&#39;, low=-2.2, high=2.2) dg.fit(batch_size=50, sampler=sampler, n_iters=200000, bar=&quot;notebook&quot;) . Now let&#39;s ask our neural network to predict the solutions given several different values of $ alpha$. . t = np.linspace(0, 10, 100) alphas = [-2.0, -1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5, 2.0] nn_sols = np.zeros((len(t), len(alphas))) for j, alpha in enumerate(alphas): alpha_vec = alpha*np.ones(len(t)) inputs = np.stack([t, alpha_vec]).T nn_sol = dg.solve(inputs)[:,0] nn_sols[:,j] = nn_sol fig, axs = plt.subplots(3, 3, figsize=(13,13)) for j, ax in enumerate(fig.axes): analytic_sol = alphas[j]*np.sin(t) ax.plot(t, nn_sols[:,j], label=&quot;Neural Network&quot;) ax.plot(t, analytic_sol, label=&quot;Analytic&quot;, linestyle=&quot;--&quot;) ax.set_title(r&quot;$ alpha = {}$&quot;.format(alphas[j])) ax.legend(loc=&quot;lower right&quot;) ax.set_ylim(-2.5, 2.5) plt.show() . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-11T12:05:02.695287 image/svg+xml Matplotlib v3.3.4, https://matplotlib.org/ Another feature of this approach is that we can get the gradient of the solution with respect to the parameters $ theta$ for free (virtually). We can calculate the gradient by using automatic differentiation, the same tool that is being used to train the neural network in the first place. If you&#39;re familiar with PyMC3, this is also the tool being used under-the-hood to get the gradients for use in the NUTS sampler. For any $t$ the analytic gradient of our ODE solution is $$ nabla_ theta , x(t) = cfrac{ partial x(t)}{ partial alpha} = sin(t). $$ Let&#39;s compare this to the gradients we get from querying our neural network. . t = np.linspace(0, 10, 100) alphas = [-2.0, -1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5, 2.0] nn_sols = np.zeros((len(t), len(alphas))) for j, alpha in enumerate(alphas): alpha_vec = alpha*np.ones(len(t)) inputs = np.stack([t, alpha_vec]).T nn_sol = dg.solve(inputs, fetches=&quot;dxdalpha&quot;)[:,0] nn_sols[:,j] = nn_sol fig, axs = plt.subplots(3, 3, figsize=(13,13)) for j, ax in enumerate(fig.axes): analytic_sol = np.sin(t) ax.plot(t, nn_sols[:,j], label=&quot;Neural Network&quot;) ax.plot(t, analytic_sol, label=&quot;Analytic&quot;, linestyle=&quot;--&quot;) ax.set_title(r&quot;$ alpha = {}$&quot;.format(alphas[j])) ax.legend(loc=&quot;lower right&quot;) ax.set_ylim(-2.5, 2.5) plt.show() . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-11T12:05:04.553610 image/svg+xml Matplotlib v3.3.4, https://matplotlib.org/ Now that we have a neural network that can solve our ODE and compute gradients, we have everything we need to perform inference with the model. . Integrating PyMC3 . We&#39;ll consider the simple inference problem of estimating $ alpha$ given a sequence of noisy observations $y_i$ of $x(t)$, i.e. $$ begin{align} cfrac{dx}{dt} &amp;= alpha cos(t), x(0) &amp;= 0, y_i &amp;= x(t_i) + varepsilon, varepsilon &amp; sim mathcal{N}(0, sigma^2), end{align} $$ for some level of noise $ sigma &gt; 0$. First let&#39;s generate some artifical data. . alpha_true = 1.3 sigma_true = 3.0 # Make fake data np.random.seed(0) dts = 0.2*np.abs(np.random.randn(50)) t_obs = dts.cumsum() x_obs = alpha_true*np.sin(t_obs) y_obs = x_obs + sigma_true*np.random.randn(len(x_obs)) . t = np.linspace(0, 10, 1000) x = alpha_true*np.sin(t) fig, axs = plt.subplots(figsize=(13,5)) axs.plot(t, x, label=&quot;True&quot;) axs.scatter(t_obs, y_obs, label=&quot;Observed&quot;, color=&quot;C1&quot;, marker=&quot;x&quot;) axs.set_xlabel(r&quot;$t$&quot;) axs.set_ylabel(r&quot;$x(t)$&quot;) axs.set_title(&quot;Artificial Data&quot;) axs.legend() plt.show() . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-11T12:05:10.221591 image/svg+xml Matplotlib v3.3.4, https://matplotlib.org/ In order to use our neural network with PyMC3 we&#39;ll write our own Theano Op that takes care of connecting it to the computational graph of a PyMC3 model. . import theano import theano.tensor as tt from theano import Op class ODEop(Op): itypes = [tt.dscalar] # expects a vector of parameter values when called otypes = [tt.dvector] # outputs a single scalar value (the log likelihood) def __init__(self, diffeq_model, t_points): self.diffeq_model = diffeq_model self.t_points = t_points self.n_points = len(self.t_points) #print(self.n_points) def perform(self, node, inputs, outputs): epsilon, = inputs #print(epsilon.shape) pts = np.concatenate([self.t_points.reshape(-1, 1), epsilon * np.ones((self.n_points, 1))], axis=1) result = np.float64(np.squeeze(self.diffeq_model.solve(pts))) outputs[0][0] = result def grad(self, inputs, g): epsilon, = inputs #Epsilon = self(epsilon) #print(epsilon.shape) pts = np.concatenate([self.t_points.reshape(-1, 1), epsilon * tt.ones_like(np.ones((self.n_points, 1)))], axis=1) result = np.float64(np.squeeze(self.diffeq_model.solve(pts, fetches=&quot;d_epsilon&quot;))) print(result) print(g*result) return [ g[0]*result ] # class ODEGradop(Op): # itypes = [tt.dscalar, tt.dvector] # otypes = [tt.dscalar] # def __init__(self, pydens_model, t_obs): # self.pydens_model = pydens_model # # Setup the input for the neural net # t_comp = np.stack([t_obs, np.zeros_like(t_obs)]).T # alpha_comp = np.stack([np.zeros_like(t_obs), np.ones_like(t_obs)]).T # self.t_comp = theano.tensor.as_tensor_variable(t_comp) # self.alpha_comp = theano.tensor.as_tensor_variable(alpha_comp) # def perform(self, node, inputs, outputs): # #print(&quot;GradOp perform() triggered&quot;) # alpha, g = inputs # nn_input = self.t_comp + alpha*self.alpha_comp # result = np.float64(self.pydens_model.solve(nn_input.eval(), fetches=&quot;dxdalpha&quot;)[:,0]) # #print(result) # outputs[0][0] = np.dot(g, result) # class ODEop(Op): # itypes = [tt.dscalar] # otypes = [tt.dvector] # def __init__(self, pydens_model, t_obs): # self.pydens_model = pydens_model # self.t_obs = t_obs # # Setup the input for the neural net # t_comp = np.stack([t_obs, np.zeros_like(t_obs)]).T # alpha_comp = np.stack([np.zeros_like(t_obs), np.ones_like(t_obs)]).T # self.t_comp = theano.tensor.as_tensor_variable(t_comp) # self.alpha_comp = theano.tensor.as_tensor_variable(alpha_comp) # def perform(self, node, inputs, outputs): # #print(&quot;Op perform() triggered&quot;) # alpha, = inputs # nn_input = self.t_comp + alpha*self.alpha_comp # result = np.float64(self.pydens_model.solve(nn_input.eval())[:,0]) # #print(&quot;Op perform: &quot;, result) # outputs[0][0] = result # def grad(self, inputs, output_grads): # #print(&quot;Op grad() triggered&quot;) # alpha, = inputs # g, = output_grads # grad_op = ODEGradop(self.pydens_model, self.t_obs) # #print(alpha.type()) # #print(g.type()) # grad_op_apply = grad_op(alpha, g) # return [grad_op_apply] # _ = self(alpha) # nn_input = self.t_comp + alpha*self.alpha_comp # gr # return [output_grads*out] # #out = self.pydens_model.solve(nn_input.eval(), fetchs=&quot;dxdalpha&quot;)[:,0] # return [output_grads*out] #g = output_grads[0] #grad_op = ODEGradop(self.pydens_model, self.t_obs) #grad_op_apply = grad_op(alpha, g) #return [g*grad_op_apply] . import pymc3 as pm . tt_PyDEnsModel = ODEop(dg, t_obs) with pm.Model() as model: # Priors alpha = pm.Uniform(&quot;alpha&quot;, lower=-2.0, upper=2.0) sigma = pm.Uniform(&quot;sigma&quot;, lower=0.3, upper=6.0) # ODE ode_sol = tt_PyDEnsModel(alpha) forward = ode_sol.reshape(y_obs.shape) # Likelihood likelihood = pm.Normal(&quot;likelihood&quot;, mu=forward, sigma=sigma, observed=y_obs) . with model: trace = pm.sample(cores=1, chains=1, draws=1000) . Auto-assigning NUTS sampler... Initializing NUTS using jitter+adapt_diag... Initializing NUTS failed. Falling back to elementwise auto-assignment. Sequential sampling (4 chains in 1 job) CompoundStep &gt;Slice: [alpha] &gt;NUTS: [sigma] . . Sampling 1 chain for 1_000 tune and 565 draw iterations (1_000 + 565 draws total) took 8 seconds. Only one chain was sampled, this makes it impossible to run some convergence checks . import arviz as az . az.plot_trace(trace) . array([[&lt;AxesSubplot:title={&#39;center&#39;:&#39;alpha&#39;}&gt;, &lt;AxesSubplot:title={&#39;center&#39;:&#39;alpha&#39;}&gt;], [&lt;AxesSubplot:title={&#39;center&#39;:&#39;sigma&#39;}&gt;, &lt;AxesSubplot:title={&#39;center&#39;:&#39;sigma&#39;}&gt;]], dtype=object) . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-10T01:56:22.242630 image/svg+xml Matplotlib v3.4.2, https://matplotlib.org/ az.plot_pair(trace, kind=&quot;kde&quot;) . &lt;AxesSubplot:xlabel=&#39;alpha&#39;, ylabel=&#39;sigma&#39;&gt; . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-10T01:59:19.740610 image/svg+xml Matplotlib v3.4.2, https://matplotlib.org/ with pm.Model() as analytic_model: # Priors alpha = pm.Uniform(&quot;alpha&quot;, lower=-2.0, upper=2.0) sigma = pm.Uniform(&quot;sigma&quot;, lower=0.3, upper=6.0) # ODE forward = pm.Deterministic(&quot;forward&quot;, alpha*tt.sin(t_obs)) # Likelihood likelihood = pm.Normal(&quot;likelihood&quot;, mu=forward, sigma=sigma, observed=y_obs) . with analytic_model: trace_analytic = pm.sample(cores=1, chains=1, draws=10000) . Auto-assigning NUTS sampler... Initializing NUTS using jitter+adapt_diag... Sequential sampling (1 chains in 1 job) NUTS: [sigma, alpha] . . Sampling 1 chain for 1_000 tune and 10_000 draw iterations (1_000 + 10_000 draws total) took 5 seconds. Only one chain was sampled, this makes it impossible to run some convergence checks . az.plot_trace(trace_analytic, var_names=[&quot;~forward&quot;]) . array([[&lt;AxesSubplot:title={&#39;center&#39;:&#39;alpha&#39;}&gt;, &lt;AxesSubplot:title={&#39;center&#39;:&#39;alpha&#39;}&gt;], [&lt;AxesSubplot:title={&#39;center&#39;:&#39;sigma&#39;}&gt;, &lt;AxesSubplot:title={&#39;center&#39;:&#39;sigma&#39;}&gt;]], dtype=object) . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-10T01:56:36.438449 image/svg+xml Matplotlib v3.4.2, https://matplotlib.org/ az.plot_pair(trace_analytic, kind=&quot;kde&quot;, var_names=[&quot;~forward&quot;]) . &lt;AxesSubplot:xlabel=&#39;alpha&#39;, ylabel=&#39;sigma&#39;&gt; . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-10T01:57:52.161684 image/svg+xml Matplotlib v3.4.2, https://matplotlib.org/ # itypes = [tt.dscalar] # expects a vector of parameter values when called # otypes = [tt.dvector] # outputs a single scalar value (the log likelihood) # def __init__(self, diffeq_model, t_points): # self.diffeq_model = diffeq_model # self.t_points = t_points # self.n_points = len(self.t_points) # self.logpgrad = # print(self.n_points) # def perform(self, node, inputs, outputs): # alpha, = inputs # #print(epsilon.shape) # #alpha_vec = alpha*np.ones(len(t)) # #inputs = np.stack([t, alpha_vec]).T # #pts = np.concatenate() # pts = np.concatenate([t_points.reshape(-1, 1), alpha * np.ones((self.n_points, 1))], axis=1) # result = np.float64(np.squeeze(self.diffeq_model.solve(pts))) # outputs[0][0] = result # def grad(self, inputs, g): # alpha, = inputs # Epsilon = self(epsilon) # print(epsilon.shape) # pts = np.concatenate([t_points.reshape(-1, 1), epsilon * tt.ones_like(np.ones((self.n_points, 1)))], axis=1) # result = np.float64(np.squeeze(self.diffeq_model.solve(pts, fetches=&quot;dxdalpha&quot;))) # return [ g*result ] . I don&#39;t think I&#39;m going to keep this example . Given the recent pandemic, you may have heard of the SIR model for infectious diseases. The SIR model is given by $$ begin{align} cfrac{dS}{dt} &amp;= - beta I S cfrac{dI}{dt} &amp;= beta I S - gamma I cfrac{dR}{dt} &amp;= gamma I end{align} $$ where $ beta, gamma &gt; 0$. We can show that $S(t) + I(t) + R(t) = 1$, which means we actually can just look at $$ begin{align} cfrac{dS}{dt} &amp;= - beta I S cfrac{dI}{dt} &amp;= beta I S - gamma I end{align} $$ and then recover $R(t)$ as $R(t) = 1 - S(t) - I(t)$. Let&#39;s fix $$ begin{align} beta &amp;= 0.1, &amp;S(0) &amp;= 0.95, gamma &amp;= 0.05, &amp;I(0) &amp;= 0.05, end{align} $$ and use scipy.integrate.odeint to approximate the solution. . import numpy as np from scipy.integrate import odeint import matplotlib.pyplot as plt import matplotlib as mpl def sir_model(y, t, beta, gamma): S, I = y dSdt = -beta*I*S dIdt = beta*I*S - gamma*I return [dSdt, dIdt] t = np.linspace(0, 250, 1000) y0 = [0.95, 0.05] beta, gamma = 0.1, 0.05 sp_sol = odeint(sir_model, y0, t, args=(beta, gamma)) . S, I = sp_sol.T R = 1.0 - S - I fig, axs = plt.subplots(figsize=(13,5)) axs.plot(t, S, label=&quot;Susceptible&quot;) axs.plot(t, I, label=&quot;Infectious&quot;) axs.plot(t, R, label=&quot;Recovered&quot;) axs.set_xlabel(&quot;Time&quot;) axs.set_ylabel(&quot;% of Population&quot;) axs.set_title(&quot;SIR Model&quot;) axs.legend() plt.show() . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-08T16:32:24.667719 image/svg+xml Matplotlib v3.4.2, https://matplotlib.org/ Ignoring the specifics for now, let&#39;s use PyDEns to train a neural network that solves the same equation ODE as above. . import os import sys import warnings warnings.filterwarnings(&#39;ignore&#39;) from tensorflow import logging logging.set_verbosity(logging.ERROR) os.environ[&#39;TF_CPP_MIN_LOG_LEVEL&#39;] = &#39;2&#39; from tqdm import tqdm_notebook import tensorflow as tf from pydens import Solver, NumpySampler, cart_prod, add_tokens from pydens import plot_loss, plot_pair_1d, plot_2d, plot_sections_2d, plot_sections_3d add_tokens() . ode = { &#39;n_dims&#39;: 1, &#39;n_funs&#39;: 2, &#39;n_eqns&#39;: 2, &#39;form&#39;: [ lambda S, I, t: D(S, t) + beta*S*I, lambda S, I, t: D(I, t) - beta*S*I + gamma*I ], &#39;initial_condition&#39;: [[0.95],[0.05]], &#39;time_multiplier&#39;: &#39;polynomial&#39;, # &#39;bind_bc_ic&#39;: True } config = { &#39;pde&#39;: ode, #&#39;optimizer&#39;: &#39;Adam&#39; # &#39;decay&#39;: {&#39;name&#39;: &#39;cyclic&#39;, &#39;learning_rate&#39;:0.001, # &#39;max_lr&#39;: 0.01, &#39;step_size&#39;: 500}, # &#39;decay&#39;: {&#39;name&#39;: &#39;invtime&#39;, &#39;learning_rate&#39;:0.01, # &#39;decay_steps&#39;: 100, &#39;decay_rate&#39;: 0.05}, # &#39;track&#39;: {&#39;dt&#39;: lambda u, t, e: D(u, t), # &#39;d_epsilon&#39;: lambda u, t, e : D(u, e)} } #sampler = NumpySampler(&#39;uniform&#39;, dim=1, low=0.0, high=30.0) dg = Solver(config) sampler = NumpySampler(&#39;uniform&#39;, dim=1, low=0.0, high=250.0) dg.fit(batch_size=50, sampler=sampler, n_iters=10000) . NameError Traceback (most recent call last) &lt;ipython-input-15-3eec1393ab71&gt; in &lt;module&gt; 25 #sampler = NumpySampler(&#39;uniform&#39;, dim=1, low=0.0, high=30.0) 26 &gt; 27 dg = Solver(config) 28 29 c: users jonathan documents jupyter notebooks pydens pydens wrapper.py in __init__(self, config, model_class, layer_size, path) 26 model_class = model_class or config.get(&#39;model_class&#39;) or TFDeepGalerkin 27 config = self.build_config(config, layer_size, path) &gt; 28 self.model = model_class(config) 29 30 c: users jonathan documents jupyter notebooks pydens pydens batchflow batchflow models tf base.py in __init__(self, *args, **kwargs) 315 &#39;devices&#39;, &#39;leading_device&#39;, &#39;device_to_scope&#39;, &#39;scope_to_device&#39;, &#39;multi_device&#39;] 316 --&gt; 317 super().__init__(*args, **kwargs) 318 319 def store_to_attr(self, attr, graph_item, device=None): c: users jonathan documents jupyter notebooks pydens pydens batchflow batchflow models base.py in __init__(self, config, *args, **kwargs) 36 self.load(**load) 37 if build: &gt; 38 self.build(*args, **kwargs) 39 40 @property c: users jonathan documents jupyter notebooks pydens pydens batchflow batchflow models tf base.py in build(self, *args, **kwargs) 384 with tf.device(device): 385 with tf.variable_scope(self.device_to_scope[device]): --&gt; 386 self.full_config = self.combine_configs() 387 self._make_inputs(config=self.full_config[&#39;inputs&#39;], 388 data_format=self.full_config.get(&#39;common/data_format&#39;, &#39;channels_last&#39;)) c: users jonathan documents jupyter notebooks pydens pydens model_tf.py in combine_configs(self) 121 122 # Count unique usages of `P` --&gt; 123 n_parameters = get_num_parameters(form[0]) 124 125 # Convert each expression to track to list c: users jonathan documents jupyter notebooks pydens pydens syntax_tree.py in get_num_parameters(form) 75 &#34;&#34;&#34; Get number of unique parameters (created via `P` letter) in the passed form.&#34;&#34;&#34; 76 n_args = len(inspect.signature(form).parameters) &gt; 77 tree = form(*[SyntaxTreeNode(&#39;_&#39; + str(i)) for i in range(n_args)]) 78 return len(get_unique_parameters(tree)) 79 &lt;ipython-input-15-3eec1393ab71&gt; in &lt;lambda&gt;(S, I, t) 4 &#39;n_eqns&#39;: 2, 5 &#39;form&#39;: [ -&gt; 6 lambda S, I, t: D(S, t) + beta*S*I, 7 lambda S, I, t: D(I, t) - beta*S*I + gamma*I 8 ], NameError: name &#39;beta&#39; is not defined . t_reshaped = t[:, None] nn_sol = dg.solve(t_reshaped) plt.plot(t, nn_sol[:,0], label=&quot;Susceptible&quot;) plt.plot(t, nn_sol[:,1], label=&quot;Infectious&quot;) # plt.plot(t, prey, label=&quot;SP Prey&quot;) # plt.plot(t, predator, label=&quot;SP Predator&quot;) # plt.title(&quot;Predator Error&quot;) plt.legend() plt.show() . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-08T16:33:47.643427 image/svg+xml Matplotlib v3.4.2, https://matplotlib.org/ Note: Save this example for later. This is tricky because of the nullclines. . Let&#39;s take a look at the Lotka-Volterra predator prey model, since this also appears in this example PyMC3 notebook and will be useful for comparison later. The Lotka-Volterra model is given by $$ begin{align} cfrac{dx}{dt} &amp;= alpha x - beta x y cfrac{dy}{dt} &amp;= - gamma y + delta xy end{align} $$ where $ alpha, beta, gamma, delta &gt; 0$. Here $y(t)$ and $x(t)$ represent the population level of some predator and prey in some ecosystem, respectively. Let&#39;s generate some synthetic data with scipy.integrate.odeint using $x(0) = 30$ and $y(0) = 50$ as our initial conditions and fixing $$ begin{align} alpha_{ text{true}} &amp;= 0.5 beta_{ text{true}} &amp;= 0.025 gamma_{ text{true}} &amp;= 0.8 delta_{ text{true}} &amp;= 0.025 end{align} $$ . import numpy as np from scipy.integrate import odeint import matplotlib.pyplot as plt import matplotlib as mpl def lotka_volterra(y, t, alpha, beta, gamma, delta): prey, predator = y dpreydt = alpha*prey - beta*prey*predator dpredatordt = -gamma*predator + delta*prey*predator return [dpreydt, dpredatordt] t = np.linspace(0, 30, 1000) y0 = [30, 50] alpha, beta, gamma, delta = 0.5, 0.025, 0.8, 0.025 sp_sol = odeint(lotka_volterra, y0, t, args=(alpha, beta, gamma, delta)) . fig, axs = plt.subplots(1,2, figsize=(13,5)) prey, predator = sp_sol.T axs[0].plot(t, prey, label=&quot;Prey&quot;) axs[0].plot(t, predator, label=&quot;Predator&quot;) axs[0].set_xlabel(&quot;Time&quot;) axs[0].set_ylabel(&quot;Population&quot;) axs[0].set_title(&quot;Lotka-Volterra Model&quot;) axs[0].legend() axs[1].plot(prey, predator) axs[1].set_xlabel(&quot;Prey Population&quot;) axs[1].set_ylabel(&quot;Predator Population&quot;) axs[1].set_title(&quot;Lotka-Volterra Phase Space&quot;) plt.show() . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-08T19:30:09.035483 image/svg+xml Matplotlib v3.4.2, https://matplotlib.org/ Ignoring the specifics of what&#39;s going on down below for now, let&#39;s use PyDEns to train a neural network that solves the same ODE as above. . # import sys # import warnings # warnings.filterwarnings(&#39;ignore&#39;) # from tensorflow import logging # logging.set_verbosity(logging.ERROR) # os.environ[&#39;TF_CPP_MIN_LOG_LEVEL&#39;] = &#39;2&#39; # from tqdm import tqdm_notebook # import tensorflow as tf # from pydens import Solver, NumpySampler, cart_prod, add_tokens # from pydens import plot_loss, plot_pair_1d, plot_2d, plot_sections_2d, plot_sections_3d # add_tokens() # ode = { # &#39;n_dims&#39;: 1, # &#39;n_funs&#39;: 2, # &#39;n_eqns&#39;: 2, # &#39;form&#39;: [ # lambda x, y, t: D(x, t) - (30/100)*(alpha*(100*x) + beta*(100*x)*(100*y)), # lambda x, y, t: D(y, t) + (30/100)*(gamma*(100*y) - delta*(100*x)*(100*y)) # ], # &#39;initial_condition&#39;: [[30/100],[50/100]], # #&#39;time_multiplier&#39;: &#39;sigmoid&#39;, # # &#39;bind_bc_ic&#39;: True # } ode = { &#39;n_dims&#39;: 1, &#39;n_funs&#39;: 2, &#39;n_eqns&#39;: 2, &#39;form&#39;: [ lambda x, y, t: D(x, t) - alpha*x + beta*x*y, lambda x, y, t: D(y, t) + gamma*y - delta*x*y ], &#39;initial_condition&#39;: [[30],[50]], #&#39;time_multiplier&#39;: &#39;sigmoid&#39;, # &#39;bind_bc_ic&#39;: True } config = { &#39;pde&#39;: ode, #&#39;optimizer&#39;: &#39;Adam&#39; # &#39;decay&#39;: {&#39;name&#39;: &#39;cyclic&#39;, &#39;learning_rate&#39;:0.001, # &#39;max_lr&#39;: 0.01, &#39;step_size&#39;: 500}, # &#39;decay&#39;: {&#39;name&#39;: &#39;invtime&#39;, &#39;learning_rate&#39;:0.01, # &#39;decay_steps&#39;: 100, &#39;decay_rate&#39;: 0.05}, # &#39;track&#39;: {&#39;dt&#39;: lambda u, t, e: D(u, t), # &#39;d_epsilon&#39;: lambda u, t, e : D(u, e)} } #sampler = NumpySampler(&#39;uniform&#39;, dim=1, low=0.0, high=30.0) dg = Solver(config) sampler = NumpySampler(&#39;uniform&#39;, dim=1, low=0.0, high=10.0) dg.fit(batch_size=50, sampler=sampler, n_iters=10000) t_reshaped = t[:, None] res = dg.solve(t_reshaped) plt.plot(t, res[:,0], label=&quot;NN Prey&quot;) plt.plot(t, res[:,1], label=&quot;NN Predator&quot;) plt.plot(t, prey, label=&quot;SP Prey&quot;) plt.plot(t, predator, label=&quot;SP Predator&quot;) plt.title(&quot;Predator Error&quot;) plt.legend() # dtm = 5.0 # tms = np.arange(1.0, 30.0+dtm, dtm) # n_iter_per_tm = 10000 # for j, tm in enumerate(tms): # sampler = NumpySampler(&#39;uniform&#39;, dim=1, low=0.0, high=tm) # dg.fit(batch_size=50, sampler=sampler, n_iters=(j+1)*n_iter_per_tm, bar=&#39;notebook&#39;) . &lt;matplotlib.legend.Legend at 0x1e140858c88&gt; . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-08T19:30:50.643472 image/svg+xml Matplotlib v3.4.2, https://matplotlib.org/ plt.plot(res[:,0], res[:,1], label=&quot;NN Prey&quot;) . [&lt;matplotlib.lines.Line2D at 0x1e140a6a208&gt;] . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-08T19:32:29.572355 image/svg+xml Matplotlib v3.4.2, https://matplotlib.org/ sampler = NumpySampler(&#39;uniform&#39;, dim=1, low=0.0, high=4.0) dg.fit(batch_size=50, sampler=sampler, n_iters=10000) t_reshaped = t[:, None] res = dg.solve(t_reshaped) plt.plot(t, res[:,0], label=&quot;NN Prey&quot;) plt.plot(t, res[:,1], label=&quot;NN Predator&quot;) plt.plot(t, prey, label=&quot;SP Prey&quot;) plt.plot(t, predator, label=&quot;SP Predator&quot;) plt.title(&quot;Predator Error&quot;) plt.legend() . &lt;matplotlib.legend.Legend at 0x1a7f7b1f188&gt; . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-08T15:33:03.881860 image/svg+xml Matplotlib v3.4.2, https://matplotlib.org/ sampler = NumpySampler(&#39;uniform&#39;, dim=1, low=0.0, high=6.0) dg.fit(batch_size=50, sampler=sampler, n_iters=10000) t_reshaped = t[:, None] res = dg.solve(t_reshaped) plt.plot(t, res[:,0], label=&quot;NN Prey&quot;) plt.plot(t, res[:,1], label=&quot;NN Predator&quot;) plt.plot(t, prey, label=&quot;SP Prey&quot;) plt.plot(t, predator, label=&quot;SP Predator&quot;) plt.title(&quot;Predator Error&quot;) plt.legend() . &lt;matplotlib.legend.Legend at 0x1a78537cec8&gt; . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-08T15:33:20.243434 image/svg+xml Matplotlib v3.4.2, https://matplotlib.org/ sampler = NumpySampler(&#39;uniform&#39;, dim=1, low=0.0, high=8.0) dg.fit(batch_size=50, sampler=sampler, n_iters=10000) t_reshaped = t[:, None] res = dg.solve(t_reshaped) plt.plot(t, res[:,0], label=&quot;NN Prey&quot;) plt.plot(t, res[:,1], label=&quot;NN Predator&quot;) plt.plot(t, prey, label=&quot;SP Prey&quot;) plt.plot(t, predator, label=&quot;SP Predator&quot;) plt.title(&quot;Predator Error&quot;) plt.legend() . &lt;matplotlib.legend.Legend at 0x1a784a6e308&gt; . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-08T15:34:55.041440 image/svg+xml Matplotlib v3.4.2, https://matplotlib.org/ sampler = NumpySampler(&#39;uniform&#39;, dim=1, low=0.0, high=8.0) dg.fit(batch_size=50, sampler=sampler, n_iters=10000) t_reshaped = t[:, None] res = dg.solve(t_reshaped) plt.plot(t, res[:,0], label=&quot;NN Prey&quot;) plt.plot(t, res[:,1], label=&quot;NN Predator&quot;) plt.plot(t, prey, label=&quot;SP Prey&quot;) plt.plot(t, predator, label=&quot;SP Predator&quot;) plt.title(&quot;Predator Error&quot;) plt.legend() . &lt;matplotlib.legend.Legend at 0x1a7fbc765c8&gt; . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-08T15:35:23.784386 image/svg+xml Matplotlib v3.4.2, https://matplotlib.org/ sampler = NumpySampler(&#39;uniform&#39;, dim=1, low=0.0, high=8.0) dg.fit(batch_size=50, sampler=sampler, n_iters=10000) t_reshaped = t[:, None] res = dg.solve(t_reshaped) plt.plot(t, res[:,0], label=&quot;NN Prey&quot;) plt.plot(t, res[:,1], label=&quot;NN Predator&quot;) plt.plot(t, prey, label=&quot;SP Prey&quot;) plt.plot(t, predator, label=&quot;SP Predator&quot;) plt.title(&quot;Predator Error&quot;) plt.legend() . &lt;matplotlib.legend.Legend at 0x1a7fae9c2c8&gt; . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-08T15:36:33.226069 image/svg+xml Matplotlib v3.4.2, https://matplotlib.org/ sampler = NumpySampler(&#39;uniform&#39;, dim=1, low=0.0, high=10.0) dg.fit(batch_size=50, sampler=sampler, n_iters=10000) t_reshaped = t[:, None] res = dg.solve(t_reshaped) plt.plot(t, res[:,0], label=&quot;NN Prey&quot;) plt.plot(t, res[:,1], label=&quot;NN Predator&quot;) plt.plot(t, prey, label=&quot;SP Prey&quot;) plt.plot(t, predator, label=&quot;SP Predator&quot;) plt.title(&quot;Predator Error&quot;) plt.legend() . &lt;matplotlib.legend.Legend at 0x1a7f2029488&gt; . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-08T15:36:49.302126 image/svg+xml Matplotlib v3.4.2, https://matplotlib.org/ sampler = NumpySampler(&#39;uniform&#39;, dim=1, low=0.0, high=10.0) dg.fit(batch_size=50, sampler=sampler, n_iters=10000) t_reshaped = t[:, None] res = dg.solve(t_reshaped) plt.plot(t, res[:,0], label=&quot;NN Prey&quot;) plt.plot(t, res[:,1], label=&quot;NN Predator&quot;) plt.plot(t, prey, label=&quot;SP Prey&quot;) plt.plot(t, predator, label=&quot;SP Predator&quot;) plt.title(&quot;Predator Error&quot;) plt.legend() . &lt;matplotlib.legend.Legend at 0x1a785363608&gt; . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-08T15:37:54.015064 image/svg+xml Matplotlib v3.4.2, https://matplotlib.org/ sampler = NumpySampler(&#39;uniform&#39;, dim=1, low=0.0, high=10.0) dg.fit(batch_size=50, sampler=sampler, n_iters=10000) t_reshaped = t[:, None] res = dg.solve(t_reshaped) plt.plot(t, res[:,0], label=&quot;NN Prey&quot;) plt.plot(t, res[:,1], label=&quot;NN Predator&quot;) plt.plot(t, prey, label=&quot;SP Prey&quot;) plt.plot(t, predator, label=&quot;SP Predator&quot;) plt.title(&quot;Predator Error&quot;) plt.legend() . &lt;matplotlib.legend.Legend at 0x1a7f57086c8&gt; . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-08T15:40:04.405164 image/svg+xml Matplotlib v3.4.2, https://matplotlib.org/ sampler = NumpySampler(&#39;uniform&#39;, dim=1, low=0.0, high=14.0) dg.fit(batch_size=50, sampler=sampler, n_iters=10000) t_reshaped = t[:, None] res = dg.solve(t_reshaped) plt.plot(t, res[:,0], label=&quot;NN Prey&quot;) plt.plot(t, res[:,1], label=&quot;NN Predator&quot;) plt.plot(t, prey, label=&quot;SP Prey&quot;) plt.plot(t, predator, label=&quot;SP Predator&quot;) plt.title(&quot;Predator Error&quot;) plt.legend() . &lt;matplotlib.legend.Legend at 0x1a7ec3cdb48&gt; . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-08T16:01:59.272580 image/svg+xml Matplotlib v3.4.2, https://matplotlib.org/ plt.plot(res[:,0], res[:,1], label=&quot;NN Prey&quot;) plt.show() . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-08T15:41:24.583617 image/svg+xml Matplotlib v3.4.2, https://matplotlib.org/ It looks like that did something exciting! Let&#39;s look at how our loss function evolved as the network was trained. . n_iters = len(dg.loss) it_idx = [i+1 for i in range(n_iters)] fig, axs = plt.subplots(1, 2, figsize=(13,5)) axs[0].plot(it_idx, dg.loss) axs[0].set_ylabel(&#39;Loss&#39;) axs[0].set_xlabel(&#39;Iteration&#39;) axs[1].plot(it_idx, dg.loss) axs[1].set_ylabel(&#39;Log Loss&#39;) axs[1].set_xlabel(&#39;Iteration&#39;) axs[1].set_yscale(&#39;log&#39;) plt.show() . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-08T15:38:27.719634 image/svg+xml Matplotlib v3.4.2, https://matplotlib.org/ plot_loss(dg.loss) . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-08T13:32:05.918283 image/svg+xml Matplotlib v3.4.2, https://matplotlib.org/ Now that we have our trained neural network, let&#39;s compare its estimated solution with the solution we got earlier from scipy.integrate.odeint. . t_reshaped = t[:, None] res = dg.solve(t_reshaped) plt.plot(t, res[:,0], label=&quot;NN Prey&quot;) plt.plot(t, res[:,1], label=&quot;NN Predator&quot;) plt.plot(t, prey, label=&quot;SP Prey&quot;) plt.plot(t, predator, label=&quot;SP Predator&quot;) plt.title(&quot;Predator Error&quot;) plt.legend() . &lt;matplotlib.legend.Legend at 0x1a7f488ea88&gt; . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-08T13:33:21.170666 image/svg+xml Matplotlib v3.4.2, https://matplotlib.org/ t_reshaped = t[:, None] res = dg.solve(t_reshaped) plt.plot(t, np.abs(prey - res[:,0]), label=&quot;Prey Error&quot;) plt.plot(t, np.abs(predator - res[:,1]), label=&quot;Predator Error&quot;) plt.title(&quot;Error&quot;) plt.legend() plt.show() . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-08T13:36:07.651416 image/svg+xml Matplotlib v3.4.2, https://matplotlib.org/ def check_if_stable(loss, lookback_its = ): &quot;&quot;&quot;Checks if the loss curve has flattened out. &quot;&quot;&quot; . np.mean(np.diff(dg.loss)) . -0.0008927509 . Now suppose that the observed data we see in reality is some sparsely-observed subset of this data, contaminated by some Gaussian noise with mean zero and variance $ sigma^2_{ text{true}} = 100.0$. Let&#39;s take a subset of the points from above and add on this noise. . t_idxs = np.arange(0, 1000, 50) t_obs = t[t_idxs] prey_obs, predator_obs = sol[t_idxs, :].T # Add on noise sigma_true = 10.0 prey_obs += sigma_true*np.random.randn(len(prey_obs)) predator_obs += sigma_true*np.random.randn(len(predator_obs)) . fig, axs = plt.subplots(figsize=(13,5)) axs.plot(t, prey, label=&quot;True Prey&quot;) axs.plot(t, predator, label=&quot;True Predator&quot;) axs.scatter(t_obs, prey_obs, label=&quot;Observed Prey&quot;) axs.scatter(t_obs, predator_obs, label=&quot;Observed Predator&quot;) axs.set_xlabel(&quot;Time&quot;) axs.set_ylabel(&quot;Population&quot;) axs.set_title(&quot;Lotka-Volterra Model&quot;) axs.legend() plt.show() . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-07T21:33:03.526145 image/svg+xml Matplotlib v3.4.2, https://matplotlib.org/ Some sources . http://mattpitkin.github.io/samplers-demo/pages/pymc3-blackbox-likelihood/ .",
            "url": "https://jlindbloom.github.io/qed404/2021/01/01/ode-inference-with-pydens-and-pymc3.html",
            "relUrl": "/2021/01/01/ode-inference-with-pydens-and-pymc3.html",
            "date": " • Jan 1, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "I am an incoming first-year applied mathematics PhD student at Dartmouth College, originally from Dallas. I like learning about computational methods for solving (inverse) problems and quantifying uncertainty. Open-source + science is pretty neat too, so sometimes I write about this here. . . I can be reached by email at jonathan@lindbloom.com. . This website is powered by fastpages and .",
          "url": "https://jlindbloom.github.io/qed404/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://jlindbloom.github.io/qed404/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}