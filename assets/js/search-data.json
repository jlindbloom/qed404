{
  
    
        "post0": {
            "title": "Accelerated Differential Equation Inference with PyDEns and PyMC3, Part I: ODEs",
            "content": "!!! This is a work-in-progress !!! . Welcome! This is the first post in a series I intend to write on how to leverage the power of neural networks to help speed up Bayesian inference for differential equations models. My rough outline is: . Part I: Ordinary Differential Equations (ODEs) | Part II: Issues with Nonlinear ODEs | Part III: Partial Differential Equations (PDEs) | Part IV: Stochastic Differential Equations (SDEs) | . This is also my first time writing a tutorial like this, so any feedback is appreciated! . Traditional Approaches . As a newcommer to the PyMC3 community about a year ago, one of the things I was most excited to learn about was using PyMC3 to perform Bayesian inference for systems of ordinary differential equations (ODEs). In order to take advantage of the efficiency of the NUTS sampler you must be able to provide gradients of the model with respect to each of the model parameters, which can be tricky for ODEs. In my experiences, ignoring the case in which you happen to know the analytic solution there seems to be three approaches to achieving this: . Write an ODE solver entirely in Theano which automatically gives you ability to get gradients via autodiff. This might seem like the easiest way to get the gradients, but you lose the confidence provided by well-tested solvers and it is hard to control the errors in the calculated gradients. | Use an ODE solver coupled with the adjoint method to get the gradients by solving an associated system of ODEs. This is what is done in the package sunode. | Use an ODE solver coupled with local sensitivity analysis to get the gradients by solving an augmented system of ODEs. This is the approach taken in the PyMC3 example on the Lotka-Volterra model with manual gradients. | However, you may have noticed that sometimes these methods can be slow. Let&#39;s try to reason about what might cause this. Suppose we are given some parametric ODE system $$ frac{d mathbf{x}}{dt} = f( mathbf{x}, t; theta) $$ with an initial condition $ mathbf{x}_0$ and would like to know both $ mathbf{x}(T)$ and $ frac{ partial mathbf{x}(T)}{ partial theta}$ for some later time $T &gt; 0$. Traditional methods for approximating $ mathbf{x}(T)$ boil down to computing a sequence of points $ { (t_j, mathbf{x}^{j}) }_{j=0}^{M}$ with the goal being that $ mathbf{x}^M approx mathbf{x}(T)$. We might compute this sequence using the Euler method or better yet a Runge-Kutta method. If we want to increase the accuracy of our approximation $ mathbf{x}^M approx mathbf{x}(T)$ we can decrease the timestep of our method which consequently lengthens the sequence of intermediary points we must compute. If all we care about is getting $ mathbf{x}^M$ correct and won&#39;t use the other points $ { mathbf{x}^{j} }_{j=0}^{M-1}$ for anything, we end up computing an awfully large amount of intermediary points we don&#39;t actually care about. Now you might point out that in practice we often get a whole time-series of observations and that actually we will be using many of these intermediary points. OK, fine. But what if our desired numerical accuracy of our solver requires a timestep that makes our observations sparse in time when compared to the granularity of our approximating sequence? This is effectively the same dilemma as before &mdash; we approximate the solution of the ODE at a ton of times that we don&#39;t actually care about it. Inference with ODEs using these methods can be slow since each step of MCMC must re-calculate these lengthy sequences of points for a different set of parameters $ theta$. If we want to speed up ODE inference, it seems like our time would be well-spent trying to avoid the calculation of these sequences at each step. The goal of this post is to introduce a new and exciting alternative to achieve this! . An Outline of the Neural Network Approach . The neural network approach to inference for ODEs involves an expensive offline step that then permits lightning-fast online inference. By offline, I mean that we can offload the computational expense associated with approximating solutions to differential equations during inference by pre-computing entire families of solutions in advance. But rather than building up a database of solutions calculated from some traditional solver and then querying/interpolating from that, we instead use a neural network to encode this information. Miraculously, training this neural network requires no reference solutions to learn from. This offline step might end up being more costly on net for a given tolerance than if we were to just approximate the solution with some traditional solver, but the point is that this approach allows us to pay this cost upfront instead of gradually over the course of an inference algorithm like MCMC. This approach will also allow us to circumvent the aforementioned burden of having to compute solutions and gradients for intermediary time points between our observations each time we query a solution of the differential equation. An extra benefit is that if we want to fit the same differential equation model to many different sets of data, we can just save and reload our neural network instead of incurring the cost of the expensive offline step each time we want to run an inference algorithm. . Thinking Differently About Differential Equations . A useful concept to introduce before we dive in is the flow map associated to an autonomous ODE. Suppose that we know we start at $ mathbf{x}_0 in mathbb{R}^d$ and want to know where in the phase space we&#39;ll be at time $t = tau$. The flow map $ Phi_ tau : mathbb{R}^d to mathbb{R}^d$ is the function that takes us from $ mathbb{x}_0$ directly to $ mathbf{x}( tau)$, as well as from any other possible initial condition $ mathbf{x}_0&#39;$ we could&#39;ve chosen to where that point would land at time $t = tau$. In other words, $$ Phi_ tau( mathbf{x}_0) = mathbb{x}( tau) $$ where $ mathbf{x}(t)$ is the solution to the initial value problem $$ begin{align} cfrac{d mathbf{x}}{dt} &amp;= f( mathbf{x}; theta) &amp; text{for $t in [0, tau]$,} mathbf{x}(0) &amp;= mathbf{x}_0 end{align} $$ and $ theta in Theta = mathbf{R}^{d_ Theta}$. If we knew the flow map $ Phi_ tau$ for any $ mathbf{x}_0 in mathbb{R}^d$ and $ tau &gt; 0$ then we wouldn&#39;t have to bother with calculating an approximating sequence with a traditional solver in order to approximate $ mathbf{x}(T)$ &mdash; we could just evaluate $ Phi_T( mathbf{x}_0) = mathbf{x}(T)$. If we also knew $ frac{ partial Phi_ tau}{ partial theta}$, the gradient of the flow map with respect to the ODE parameters, we would have all of the requisite information we need to then proceed with using a gradient-based sampler like NUTS. Our approach will be valid for non-autonomous ODEs as well, so my introduction of the flow map was really just to get you warmed up to the idea of the solution operator $ Phi: mathbb{R}^1 times mathbb{R}^d times mathbb{R}^{d_ Theta} to mathbb{R}^d$. By solution operator, we refer to the function that accepts some $t geq 0$, an initial condition $ mathbf{x}_0 in mathbb{R}^d$, and some set of parameters $ theta in mathbb{R}^{d_ Theta}$, which then returns the solution $x(t) = Phi(t, mathbf{x}_0, theta)$ to the initial value problem. While we can extend this idea to boundary value problems and PDEs as well, for the meantime we&#39;ll just stick with IVPs for ODEs. The neural network approach is based on the idea of trying to directly approximate $ Phi$ and $ frac{ partial Phi}{ partial theta}$. . Using Neural Networks to Solve ODEs . If you&#39;re reading this post and don&#39;t know much about neural networks, don&#39;t worry &mdash; I&#39;m no expert either. In this post, a &quot;neural network&quot; simply refers to some function $F_{ mathcal{ eta}} : mathbb{R}^{d_1} to mathbb{R}^{d_2}$ where $ eta$ represents some set of trainable parameters (treat these completely separate from our model parameters $ theta$). By &quot;trainable&quot; I mean that we can tweak $ eta$ in order to get $F_ eta$ to &quot;agree&quot; with some other function $G: mathbb{R}^d to mathbb{R}^d$, and by &quot;agree&quot; I mean that given some set of points $ P subset mathbb{R}^{d_1} $ we can tweak $ eta$ to get $F_ eta( mathbf{x}) approx G( mathbf{x})$ for $ mathbf{x} in P$. Referring back to the idea of the solution operator $ Phi$, what if we took $d_1 = 1 + d + d_ Theta$, $d_2=d$, and then tried to train $F_ eta$ to agree with $ Phi$? . Enter PyDEns, a Python package for solving differential equations with neural networks that does just this. I will not go into the specifics here of how to use PyDEns or the theory of what is going on under the hood since the PyDEns developers provide an excellent series of tutorial notebooks here. Perhaps it&#39;s best to start with an example of PyDEns in action. $$ cfrac{dx}{dt} = cos(t) $$ with some initial condition $x(0) = x_0$, for which we know that the analytic solution is $$ x(t) = sin(t) + x_0. $$ Ignoring the specifics of what&#39;s going on down below, let&#39;s fix $x_0 = 0$ and use PyDEns to train a neural network that solves this ODE. . import pymc3 as pm import arviz as az . import os import sys import warnings warnings.filterwarnings(&#39;ignore&#39;) from tensorflow import logging logging.set_verbosity(logging.ERROR) os.environ[&#39;TF_CPP_MIN_LOG_LEVEL&#39;] = &#39;2&#39; from tqdm import tqdm_notebook import tensorflow as tf from pydens import Solver, NumpySampler, cart_prod, add_tokens from pydens import plot_loss, plot_pair_1d, plot_2d, plot_sections_2d, plot_sections_3d import numpy as np import matplotlib.pyplot as plt add_tokens() . . ode = { &#39;n_dims&#39;: 1, &#39;form&#39;: lambda u, t : D(u, t) - cos(t), &#39;initial_condition&#39;: 0.0, } config = { &#39;pde&#39;: ode, } dg = Solver(config) sampler = NumpySampler(&#39;uniform&#39;, dim=1, low=0.0, high=10.0) dg.fit(batch_size=50, sampler=sampler, n_iters=100000, bar=&quot;notebook&quot;) . That looks like it did something exciting! Let&#39;s look at the solution that our neural network predicts. . t = np.linspace(0, 10, 100) # Get the NN solution t_reshaped = t[:, None] nn_sol = dg.solve(t_reshaped)[:,0] # Get the analytic solution analytic_sol = np.sin(t) # Get the error error = np.abs(analytic_sol - nn_sol) # Plot fig, axs = plt.subplots(1, 2, figsize=(13,5)) # The solutions axs[0].plot(t, nn_sol, label=&quot;Neural Network&quot;) axs[0].plot(t, analytic_sol, label=&quot;Analytic&quot;, linestyle=&quot;--&quot;) axs[0].set_xlabel(r&quot;$t$&quot;) axs[0].set_ylabel(r&quot;$x(t)$&quot;) axs[0].set_title(&quot;Solution&quot;) axs[0].legend() # The error axs[1].plot(t, error) axs[1].set_xlabel(r&quot;$t$&quot;) axs[1].set_ylabel(&quot;Absolute Error&quot;) axs[1].set_title(&quot;Solution Error&quot;) plt.show() . . That looks pretty accurate! Perhaps you&#39;re unimpressed since all we did was learn a simple sine curve, so let&#39;s try to learn to solve an entire parametric family of ODEs by adding a parameter to this ODE $$ cfrac{dx}{dt} = alpha cos(t) $$ with fixed $x_0 = 0$. The analytic solution for this ODE is just $$ x(t) = alpha sin(t) + x_0. $$ One feature of this approach is that we must specify the range of values we would like to train the parameters over. In this example, we&#39;ll train the neural network to solve the ODE for $ alpha in [-3, 3]$. . ode = { &#39;n_dims&#39;: 1, &#39;form&#39;: lambda u, t, alpha : D(u, t) - P(alpha)*cos(t), &#39;initial_condition&#39;: 0.0, } config = { &#39;pde&#39;: ode, &#39;track&#39;: {&#39;dxdalpha&#39;: lambda u, t, alpha: D(u, alpha)} } dg = Solver(config) sampler = NumpySampler(&#39;uniform&#39;, low=0.0, high=10.0) &amp; NumpySampler(&#39;uniform&#39;, low=-2.2, high=2.2) dg.fit(batch_size=50, sampler=sampler, n_iters=200000, bar=&quot;notebook&quot;) . Now let&#39;s ask our neural network to predict the solutions given several different values of $ alpha$. . t = np.linspace(0, 10, 100) alphas = [-2.0, -1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5, 2.0] nn_sols = np.zeros((len(t), len(alphas))) for j, alpha in enumerate(alphas): alpha_vec = alpha*np.ones(len(t)) inputs = np.stack([t, alpha_vec]).T nn_sol = dg.solve(inputs)[:,0] nn_sols[:,j] = nn_sol fig, axs = plt.subplots(3, 3, figsize=(13,13)) for j, ax in enumerate(fig.axes): analytic_sol = alphas[j]*np.sin(t) ax.plot(t, nn_sols[:,j], label=&quot;Neural Network&quot;) ax.plot(t, analytic_sol, label=&quot;Analytic&quot;, linestyle=&quot;--&quot;) ax.set_title(r&quot;$ alpha = {}$&quot;.format(alphas[j])) ax.legend(loc=&quot;lower right&quot;) ax.set_ylim(-2.5, 2.5) plt.show() . . Another feature of this approach is that we can get the gradient of the solution with respect to the parameters $ theta$ for free (virtually). We can calculate the gradient by using automatic differentiation, the same tool that is being used to train the neural network in the first place. If you&#39;re familiar with PyMC3, this is also the tool being used under-the-hood to get the gradients for use in the NUTS sampler. For any $t$ the analytic gradient of our ODE solution is $$ cfrac{ partial x(t)}{ partial alpha} = sin(t). $$ Let&#39;s compare this to the gradients we get from querying our neural network. . t = np.linspace(0, 10, 100) alphas = [-2.0, -1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5, 2.0] nn_sols = np.zeros((len(t), len(alphas))) for j, alpha in enumerate(alphas): alpha_vec = alpha*np.ones(len(t)) inputs = np.stack([t, alpha_vec]).T nn_sol = dg.solve(inputs, fetches=&quot;dxdalpha&quot;)[:,0] nn_sols[:,j] = nn_sol fig, axs = plt.subplots(3, 3, figsize=(13,13)) for j, ax in enumerate(fig.axes): analytic_sol = np.sin(t) ax.plot(t, nn_sols[:,j], label=&quot;Neural Network&quot;) ax.plot(t, analytic_sol, label=&quot;Analytic&quot;, linestyle=&quot;--&quot;) ax.set_title(r&quot;$ alpha = {}$&quot;.format(alphas[j])) ax.legend(loc=&quot;lower right&quot;) ax.set_ylim(-2.5, 2.5) plt.show() . . Now that we have a neural network that can solve our ODE and compute gradients, we have everything we need to perform inference with the model. . Integrating PyMC3 . We&#39;ll consider the simple inference problem of estimating $ alpha$ given a sequence of noisy observations $ { y_i }_{i=0}^{M}$ of $x(t)$, i.e. $$ begin{align} cfrac{dx}{dt} &amp;= alpha cos(t), x(0) &amp;= 0, y_i &amp;= x(t_i) + varepsilon, varepsilon &amp; sim mathcal{N}(0, sigma^2), end{align} $$ for some level of noise $ sigma &gt; 0$. First, let&#39;s generate some artifical data. . alpha_true = 1.3 sigma_true = 3.0 # Make fake data np.random.seed(0) dts = 0.2*np.abs(np.random.randn(50)) t_obs = dts.cumsum() x_obs = alpha_true*np.sin(t_obs) y_obs = x_obs + sigma_true*np.random.randn(len(x_obs)) . t = np.linspace(0, 10, 1000) x = alpha_true*np.sin(t) fig, axs = plt.subplots(figsize=(13,5)) axs.plot(t, x, label=&quot;True&quot;) axs.scatter(t_obs, y_obs, label=&quot;Observed&quot;, color=&quot;C1&quot;, marker=&quot;x&quot;) axs.set_xlabel(r&quot;$t$&quot;) axs.set_ylabel(r&quot;$x(t)$&quot;) axs.set_title(&quot;Artificial Data&quot;) axs.legend() plt.show() . . In order to use our neural network with PyMC3 we&#39;ll write our own Theano Op that takes care of connecting it to the computational graph of a PyMC3 model. Writing this Op is the trickiest part of getting this all to work, code-wise. . import theano import theano.tensor as tt from theano import Op # Define the Theano Op for computing the gradient w.r.t. theta class ODEGradop(Op): itypes = [tt.dscalar, tt.dvector] otypes = [tt.dscalar] def __init__(self, pydens_model, t_obs): self.pydens_model = pydens_model # Setup the input for the neural net self.t_comp = np.stack([t_obs, np.zeros_like(t_obs)]).T self.theta_comp = np.stack([np.zeros_like(t_obs), np.ones_like(t_obs)]).T def perform(self, node, inputs, outputs): theta, g = inputs nn_input = self.t_comp + theta*self.theta_comp result = np.float64(np.squeeze(self.pydens_model.solve(nn_input, fetches=&quot;dxdalpha&quot;))) outputs[0][0] = np.dot(result, g) # Define the Theano Op for querying the solution of the ODE for any input theta class ODEop(Op): itypes = [tt.dscalar] otypes = [tt.dvector] def __init__(self, pydens_model, t_obs): self.pydens_model = pydens_model self.t_obs = t_obs # Setup the input for the neural net self.t_comp = np.stack([t_obs, np.zeros_like(t_obs)]).T self.theta_comp = np.stack([np.zeros_like(t_obs), np.ones_like(t_obs)]).T def perform(self, node, inputs, outputs): theta, = inputs nn_input = self.t_comp + theta*self.theta_comp result = np.float64(np.squeeze(self.pydens_model.solve(nn_input))) outputs[0][0] = result def grad(self, inputs, output_grads): x, = inputs g, = output_grads grad_op = ODEGradop(self.pydens_model, self.t_obs) grad_op_apply = grad_op(x, g) return [grad_op_apply] . Now we can easily proceed with defining a PyMC3 model, sampling the posterior, and generating some plots to analyze the results just like we normally would with any other model. . PyDEnsModel = ODEop(dg, t_obs) with pm.Model() as model: # Priors alpha = pm.Uniform(&quot;alpha&quot;, lower=-2.0, upper=2.0) sigma = pm.Uniform(&quot;sigma&quot;, lower=0.3, upper=6.0) # ODE ode_sol = PyDEnsModel(alpha) forward = pm.Deterministic(&#39;forward&#39;, ode_sol.reshape(y_obs.shape)) # Likelihood likelihood = pm.Normal(&quot;likelihood&quot;, mu=forward, sigma=sigma, observed=y_obs) # Sample the posterior trace = pm.sample(draws=10000, chains=1, cores=1) . Auto-assigning NUTS sampler... Initializing NUTS using jitter+adapt_diag... Sequential sampling (1 chains in 1 job) NUTS: [sigma, alpha] . . 100.00% [11000/11000 01:48&lt;00:00 Sampling chain 0, 0 divergences] Sampling 1 chain for 1_000 tune and 10_000 draw iterations (1_000 + 10_000 draws total) took 109 seconds. Only one chain was sampled, this makes it impossible to run some convergence checks . az.plot_trace(trace, var_names=[&quot;~forward&quot;]) . . array([[&lt;AxesSubplot:title={&#39;center&#39;:&#39;alpha&#39;}&gt;, &lt;AxesSubplot:title={&#39;center&#39;:&#39;alpha&#39;}&gt;], [&lt;AxesSubplot:title={&#39;center&#39;:&#39;sigma&#39;}&gt;, &lt;AxesSubplot:title={&#39;center&#39;:&#39;sigma&#39;}&gt;]], dtype=object) . az.plot_pair(trace, kind=&quot;kde&quot;, var_names=[&quot;~forward&quot;]) . . &lt;AxesSubplot:xlabel=&#39;alpha&#39;, ylabel=&#39;sigma&#39;&gt; . # Note: the HDI bands can be extended to the bounds of the true curve, but # we&#39;d have to do a bit of extra legwork to get this fig, axs = plt.subplots(figsize=(13,5)) axs = az.plot_hdi(t_obs, trace[&#39;forward&#39;], ax=axs, color=&quot;C2&quot;, hdi_prob=0.95) axs.plot(t, x, label=&quot;True&quot;) axs.set_title(&quot;True Solution vs. 95 % HDI&quot;) axs.set_ylabel(r&quot;$x(t)$&quot;) axs.set_xlabel(&quot;t&quot;) axs.legend() plt.show() . . Let&#39;s look at the posterior predictive. . with model: ppc = pm.sample_posterior_predictive(trace) . . 100.00% [10000/10000 00:12&lt;00:00] fig, axs = plt.subplots(figsize=(13,5)) axs = az.plot_hdi(t_obs, ppc[&#39;likelihood&#39;], color=&quot;C2&quot;, ax=axs, hdi_prob=0.95) axs.scatter(t_obs, y_obs, label=&quot;Observed&quot;, color=&quot;C1&quot;, marker=&quot;x&quot;) axs.legend() axs.set_title(&quot;Posterior Predictive 95 % HDI&quot;) axs.set_xlabel(r&quot;$t$&quot;) axs.set_ylabel(r&quot;$x(t)$&quot;) plt.show() . . Recall that we actually know the analytic solution for this simple ODE. It is easy enough for use to perform MCMC directly with these formulas in order to validate the results from the neural network approach. . with pm.Model() as analytic_model: # Priors alpha = pm.Uniform(&quot;alpha&quot;, lower=-2.0, upper=2.0) sigma = pm.Uniform(&quot;sigma&quot;, lower=0.3, upper=6.0) # ODE forward = pm.Deterministic(&#39;forward&#39;, alpha*tt.sin(t_obs)) # Likelihood likelihood = pm.Normal(&quot;likelihood&quot;, mu=forward, sigma=sigma, observed=y_obs) # Sample the posterior trace = pm.sample(draws=10000, chains=1, cores=1) . Auto-assigning NUTS sampler... Initializing NUTS using jitter+adapt_diag... Sequential sampling (1 chains in 1 job) NUTS: [sigma, alpha] . . 100.00% [11000/11000 00:04&lt;00:00 Sampling chain 0, 0 divergences] Sampling 1 chain for 1_000 tune and 10_000 draw iterations (1_000 + 10_000 draws total) took 5 seconds. Only one chain was sampled, this makes it impossible to run some convergence checks . az.plot_trace(trace, var_names=[&quot;~forward&quot;]) . . array([[&lt;AxesSubplot:title={&#39;center&#39;:&#39;alpha&#39;}&gt;, &lt;AxesSubplot:title={&#39;center&#39;:&#39;alpha&#39;}&gt;], [&lt;AxesSubplot:title={&#39;center&#39;:&#39;sigma&#39;}&gt;, &lt;AxesSubplot:title={&#39;center&#39;:&#39;sigma&#39;}&gt;]], dtype=object) . az.plot_pair(trace, kind=&quot;kde&quot;, var_names=[&quot;~forward&quot;]) . . &lt;AxesSubplot:xlabel=&#39;alpha&#39;, ylabel=&#39;sigma&#39;&gt; . The First Pitfall . You might have picked up on the fact that earlier we trained the neural network to learn the solution over $ alpha in [-2, 2]$, and in our PyMC3 model above we imposed a uniform prior $ alpha sim text{Uniform}([-2, 2])$. This was intentional. When we go to train a neural network to solve a parametric family of ODEs, it will only learn the solution over the bounds of the parameters that we input &amp;mdash querying the neural network for parameters outside of these bounds will likely return nonsensical results. It is for this reason that we chose a prior for $ alpha$ whose support laid within the interval we trained over. This brings up a potential drawback of this approach: we must either a prior pick reasonable intervals to train the parameters over such that the posterior lies within these bounds, or we must put zero prior density outside of the parameter space we trained the neural network on. In the trace and pair plots above you may have noticed that the posterior appears to hug the boundary $ alpha = 2$, which is often a symptom of picking a bad prior (unless we really did mean to restrict it like this). Let&#39;s redo the analysis above, but this time train the network to learn the solutions for $ alpha in [0, 3]$. . ode = { &#39;n_dims&#39;: 1, &#39;form&#39;: lambda u, t, alpha : D(u, t) - P(alpha)*cos(t), &#39;initial_condition&#39;: 0.0, } config = { &#39;pde&#39;: ode, &#39;track&#39;: {&#39;dxdalpha&#39;: lambda u, t, alpha: D(u, alpha)} } dg = Solver(config) sampler = NumpySampler(&#39;uniform&#39;, low=0.0, high=10.0) &amp; NumpySampler(&#39;uniform&#39;, low=-0.2, high=3.2) dg.fit(batch_size=50, sampler=sampler, n_iters=200000, bar=&quot;notebook&quot;) PyDEnsModel = ODEop(dg, t_obs) with pm.Model() as model: # Priors alpha = pm.Uniform(&quot;alpha&quot;, lower=0.0, upper=3.0) sigma = pm.Uniform(&quot;sigma&quot;, lower=0.3, upper=6.0) # ODE ode_sol = PyDEnsModel(alpha) forward = pm.Deterministic(&#39;forward&#39;, ode_sol.reshape(y_obs.shape)) # Likelihood likelihood = pm.Normal(&quot;likelihood&quot;, mu=forward, sigma=sigma, observed=y_obs) # Sample the posterior trace = pm.sample(draws=10000, chains=1, cores=1) . Auto-assigning NUTS sampler... Initializing NUTS using jitter+adapt_diag... Sequential sampling (1 chains in 1 job) NUTS: [sigma, alpha] . . 100.00% [11000/11000 01:56&lt;00:00 Sampling chain 0, 0 divergences] Sampling 1 chain for 1_000 tune and 10_000 draw iterations (1_000 + 10_000 draws total) took 116 seconds. The acceptance probability does not match the target. It is 0.88067434779255, but should be close to 0.8. Try to increase the number of tuning steps. Only one chain was sampled, this makes it impossible to run some convergence checks . az.plot_trace(trace, var_names=[&quot;~forward&quot;]) . . array([[&lt;AxesSubplot:title={&#39;center&#39;:&#39;alpha&#39;}&gt;, &lt;AxesSubplot:title={&#39;center&#39;:&#39;alpha&#39;}&gt;], [&lt;AxesSubplot:title={&#39;center&#39;:&#39;sigma&#39;}&gt;, &lt;AxesSubplot:title={&#39;center&#39;:&#39;sigma&#39;}&gt;]], dtype=object) . az.plot_pair(trace, kind=&quot;kde&quot;, var_names=[&quot;~forward&quot;]) . . &lt;AxesSubplot:xlabel=&#39;alpha&#39;, ylabel=&#39;sigma&#39;&gt; . That looks much better! . Another Example: The SIR Model . Given the recent pandemic, you may have heard of the SIR model for infectious diseases. The SIR model is given by $$ begin{align} cfrac{dS}{dt} &amp;= - beta I S cfrac{dI}{dt} &amp;= beta I S - gamma I cfrac{dR}{dt} &amp;= gamma I end{align} $$ where $ beta, gamma &gt; 0$. We can show that $S(t) + I(t) + R(t) = 1$, which means we actually can just look at $$ begin{align} cfrac{dS}{dt} &amp;= - beta I S cfrac{dI}{dt} &amp;= beta I S - gamma I end{align} $$ and then recover $R(t)$ as $R(t) = 1 - S(t) - I(t)$. Let&#39;s fix $$ begin{align} beta &amp;= 0.1, &amp;S(0) &amp;= 0.95, gamma &amp;= 0.05, &amp;I(0) &amp;= 0.05, end{align} $$ and use scipy.integrate.odeint to approximate the solution. . import numpy as np from scipy.integrate import odeint import matplotlib.pyplot as plt import matplotlib as mpl def sir_model(y, t, beta, gamma): S, I = y dSdt = -beta*I*S dIdt = beta*I*S - gamma*I return [dSdt, dIdt] t = np.linspace(0, 250, 1000) y0 = [0.95, 0.05] beta, gamma = 0.1, 0.05 sp_sol = odeint(sir_model, y0, t, args=(beta, gamma)) . S_sp, I_sp = sp_sol.T R_sp = 1.0 - S_sp - I_sp fig, axs = plt.subplots(figsize=(13,5)) axs.plot(t, S_sp, label=&quot;Susceptible&quot;) axs.plot(t, I_sp, label=&quot;Infectious&quot;) axs.plot(t, R_sp, label=&quot;Recovered&quot;) axs.set_xlabel(&quot;Time&quot;) axs.set_ylabel(&quot;% of Population&quot;) axs.set_title(&quot;SciPy Solution of SIR Model&quot;) axs.legend() plt.show() . . Let&#39;s train a neural network that learns to solve the same SIR model as above. . ode = { &#39;n_dims&#39;: 1, &#39;n_funs&#39;: 2, &#39;n_eqns&#39;: 2, &#39;form&#39;: [ lambda S, I, t: D(S, t) + beta*S*I, lambda S, I, t: D(I, t) - beta*S*I + gamma*I ], &#39;initial_condition&#39;: [[0.95],[0.05]], #&#39;time_multiplier&#39;: &#39;polynomial&#39;, # &#39;bind_bc_ic&#39;: True } config = { &#39;pde&#39;: ode, } dg = Solver(config) for high in [25.0, 50.0, 75.0, 100.0, 125.0, 150.0, 175.0, 200.0, 225.0, 250.0]: sampler = NumpySampler(&#39;uniform&#39;, dim=1, low=0.0, high=high) dg.fit(batch_size=50, sampler=sampler, n_iters=20000) . S_nn, I_nn = nn_sol[:,0], nn_sol[:,1] R_nn = 1.0 - S_nn - I_nn fig, axs = plt.subplots(2, 1, figsize=(13,10)) axs[0].plot(t, S_sp, label=&quot;Susceptible&quot;) axs[0].plot(t, I_sp, label=&quot;Infectious&quot;) axs[0].plot(t, R_sp, label=&quot;Recovered&quot;) axs[0].set_xlabel(r&quot;$t$&quot;) axs[0].set_ylabel(r&quot; % of Population&quot;) axs[0].set_title(&quot;Neural Network Solution of the SIR Model&quot;) axs[0].legend() axs[1].plot(t, np.abs(S_nn-S_sp), label=&quot;Susceptible&quot;) axs[1].plot(t, np.abs(I_nn-I_sp), label=&quot;Infectious&quot;) axs[1].plot(t, np.abs(R_nn-R_sp), label=&quot;Recovered&quot;) axs[1].set_xlabel(r&quot;$t$&quot;) axs[1].set_ylabel(&quot;Absolute Error&quot;) axs[1].set_title(&quot;Error in Neural Network Solution from SciPy Solution&quot;) axs[1].legend() plt.show() . . While we absolutely can train neural networks to learn solutions for varying initial conditions, I don&#39;t think this is possible to do within the PyDEns framework. This would make it hard to fit a neural network using PyDEns Suppose we were presented with the following COVID-19 data for infections in the United States: . import pandas as pd df = pd.read_csv(&quot;https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv&quot;) . df.head() . UID iso2 iso3 code3 FIPS Admin2 Province_State Country_Region Lat Long_ ... 7/2/21 7/3/21 7/4/21 7/5/21 7/6/21 7/7/21 7/8/21 7/9/21 7/10/21 7/11/21 . 0 84001001 | US | USA | 840 | 1001.0 | Autauga | Alabama | US | 32.539527 | -86.644082 | ... | 7262 | 7262 | 7262 | 7262 | 7262 | 7277 | 7277 | 7294 | 7299 | 7299 | . 1 84001003 | US | USA | 840 | 1003.0 | Baldwin | Alabama | US | 30.727750 | -87.722071 | ... | 22043 | 22043 | 22043 | 22043 | 22043 | 22154 | 22154 | 22220 | 22267 | 22267 | . 2 84001005 | US | USA | 840 | 1005.0 | Barbour | Alabama | US | 31.868263 | -85.387129 | ... | 2347 | 2347 | 2347 | 2347 | 2347 | 2354 | 2354 | 2361 | 2365 | 2365 | . 3 84001007 | US | USA | 840 | 1007.0 | Bibb | Alabama | US | 32.996421 | -87.125115 | ... | 2693 | 2693 | 2693 | 2693 | 2693 | 2699 | 2699 | 2699 | 2702 | 2702 | . 4 84001009 | US | USA | 840 | 1009.0 | Blount | Alabama | US | 33.982109 | -86.567906 | ... | 6988 | 6988 | 6988 | 6988 | 6988 | 7013 | 7013 | 7018 | 7023 | 7023 | . 5 rows × 548 columns . I don&#39;t think I&#39;m going to keep this example . Given the recent pandemic, you may have heard of the SIR model for infectious diseases. The SIR model is given by $$ begin{align} cfrac{dS}{dt} &amp;= - beta I S cfrac{dI}{dt} &amp;= beta I S - gamma I cfrac{dR}{dt} &amp;= gamma I end{align} $$ where $ beta, gamma &gt; 0$. We can show that $S(t) + I(t) + R(t) = 1$, which means we actually can just look at $$ begin{align} cfrac{dS}{dt} &amp;= - beta I S cfrac{dI}{dt} &amp;= beta I S - gamma I end{align} $$ and then recover $R(t)$ as $R(t) = 1 - S(t) - I(t)$. Let&#39;s fix $$ begin{align} beta &amp;= 0.1, &amp;S(0) &amp;= 0.95, gamma &amp;= 0.05, &amp;I(0) &amp;= 0.05, end{align} $$ and use scipy.integrate.odeint to approximate the solution. . import numpy as np from scipy.integrate import odeint import matplotlib.pyplot as plt import matplotlib as mpl def sir_model(y, t, beta, gamma): S, I = y dSdt = -beta*I*S dIdt = beta*I*S - gamma*I return [dSdt, dIdt] t = np.linspace(0, 250, 1000) y0 = [0.95, 0.05] beta, gamma = 0.1, 0.05 sp_sol = odeint(sir_model, y0, t, args=(beta, gamma)) . S, I = sp_sol.T R = 1.0 - S - I fig, axs = plt.subplots(figsize=(13,5)) axs.plot(t, S, label=&quot;Susceptible&quot;) axs.plot(t, I, label=&quot;Infectious&quot;) axs.plot(t, R, label=&quot;Recovered&quot;) axs.set_xlabel(&quot;Time&quot;) axs.set_ylabel(&quot;% of Population&quot;) axs.set_title(&quot;SIR Model&quot;) axs.legend() plt.show() . . Let&#39;s train a neural network that learns to solve the same SIR model as above. . ode = { &#39;n_dims&#39;: 1, &#39;n_funs&#39;: 2, &#39;n_eqns&#39;: 2, &#39;form&#39;: [ lambda S, I, t: D(S, t) + beta*S*I, lambda S, I, t: D(I, t) - beta*S*I + gamma*I ], &#39;initial_condition&#39;: [[0.95],[0.05]], #&#39;time_multiplier&#39;: &#39;polynomial&#39;, # &#39;bind_bc_ic&#39;: True } config = { &#39;pde&#39;: ode, } dg = Solver(config) for high in [25.0, 50.0, 75.0, 100.0, 125.0, 150.0, 175.0, 200.0, 225.0, 250.0]: sampler = NumpySampler(&#39;uniform&#39;, dim=1, low=0.0, high=high) dg.fit(batch_size=50, sampler=sampler, n_iters=20000) . S_nn, I_nn = nn_sol[:,0], nn_sol[:,1] R_nn = 1.0 - S_nn - I_nn fig, axs = plt.subplots(figsize=(13,5)) axs.plot(t, S_nn, label=&quot;Susceptible&quot;) axs.plot(t, I_nn, label=&quot;Infectious&quot;) axs.plot(t, R_nn, label=&quot;Recovered&quot;) axs.set_xlabel(&quot;Time&quot;) axs.set_ylabel(&quot;% of Population&quot;) axs.set_title(&quot;SIR Model&quot;) axs.legend() plt.show() . . S_nn, I_nn = nn_sol[:,0], nn_sol[:,1] R_nn = 1.0 - S_nn - I_nn fig, axs = plt.subplots(figsize=(13,5)) axs.plot(t, np.abs(S_nn-S), label=&quot;Susceptible&quot;) axs.plot(t, np.abs(I_nn-I), label=&quot;Infectious&quot;) axs.plot(t, np.abs(R_nn-R), label=&quot;Recovered&quot;) axs.set_xlabel(&quot;Time&quot;) axs.set_ylabel(&quot;% of Population&quot;) axs.set_title(&quot;SIR Model&quot;) axs.legend() plt.show() . . Note: Save this example for later. This is tricky because of the nullclines. . Let&#39;s take a look at the Lotka-Volterra predator prey model, since this also appears in this example PyMC3 notebook and will be useful for comparison later. The Lotka-Volterra model is given by $$ begin{align} cfrac{dx}{dt} &amp;= alpha x - beta x y cfrac{dy}{dt} &amp;= - gamma y + delta xy end{align} $$ where $ alpha, beta, gamma, delta &gt; 0$. Here $y(t)$ and $x(t)$ represent the population level of some predator and prey in some ecosystem, respectively. Let&#39;s generate some synthetic data with scipy.integrate.odeint using $x(0) = 30$ and $y(0) = 50$ as our initial conditions and fixing $$ begin{align} alpha_{ text{true}} &amp;= 0.5 beta_{ text{true}} &amp;= 0.025 gamma_{ text{true}} &amp;= 0.8 delta_{ text{true}} &amp;= 0.025 end{align} $$ . import numpy as np from scipy.integrate import odeint import matplotlib.pyplot as plt import matplotlib as mpl def lotka_volterra(y, t, alpha, beta, gamma, delta): prey, predator = y dpreydt = alpha*prey - beta*prey*predator dpredatordt = -gamma*predator + delta*prey*predator return [dpreydt, dpredatordt] t = np.linspace(0, 30, 1000) y0 = [30, 50] alpha, beta, gamma, delta = 0.5, 0.025, 0.8, 0.025 sp_sol = odeint(lotka_volterra, y0, t, args=(alpha, beta, gamma, delta)) . fig, axs = plt.subplots(1,2, figsize=(13,5)) prey, predator = sp_sol.T axs[0].plot(t, prey, label=&quot;Prey&quot;) axs[0].plot(t, predator, label=&quot;Predator&quot;) axs[0].set_xlabel(&quot;Time&quot;) axs[0].set_ylabel(&quot;Population&quot;) axs[0].set_title(&quot;Lotka-Volterra Model&quot;) axs[0].legend() axs[1].plot(prey, predator) axs[1].set_xlabel(&quot;Prey Population&quot;) axs[1].set_ylabel(&quot;Predator Population&quot;) axs[1].set_title(&quot;Lotka-Volterra Phase Space&quot;) plt.show() . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-08T19:30:09.035483 image/svg+xml Matplotlib v3.4.2, https://matplotlib.org/ Ignoring the specifics of what&#39;s going on down below for now, let&#39;s use PyDEns to train a neural network that solves the same ODE as above. . # import sys # import warnings # warnings.filterwarnings(&#39;ignore&#39;) # from tensorflow import logging # logging.set_verbosity(logging.ERROR) # os.environ[&#39;TF_CPP_MIN_LOG_LEVEL&#39;] = &#39;2&#39; # from tqdm import tqdm_notebook # import tensorflow as tf # from pydens import Solver, NumpySampler, cart_prod, add_tokens # from pydens import plot_loss, plot_pair_1d, plot_2d, plot_sections_2d, plot_sections_3d # add_tokens() # ode = { # &#39;n_dims&#39;: 1, # &#39;n_funs&#39;: 2, # &#39;n_eqns&#39;: 2, # &#39;form&#39;: [ # lambda x, y, t: D(x, t) - (30/100)*(alpha*(100*x) + beta*(100*x)*(100*y)), # lambda x, y, t: D(y, t) + (30/100)*(gamma*(100*y) - delta*(100*x)*(100*y)) # ], # &#39;initial_condition&#39;: [[30/100],[50/100]], # #&#39;time_multiplier&#39;: &#39;sigmoid&#39;, # # &#39;bind_bc_ic&#39;: True # } ode = { &#39;n_dims&#39;: 1, &#39;n_funs&#39;: 2, &#39;n_eqns&#39;: 2, &#39;form&#39;: [ lambda x, y, t: D(x, t) - alpha*x + beta*x*y, lambda x, y, t: D(y, t) + gamma*y - delta*x*y ], &#39;initial_condition&#39;: [[30],[50]], #&#39;time_multiplier&#39;: &#39;sigmoid&#39;, # &#39;bind_bc_ic&#39;: True } config = { &#39;pde&#39;: ode, #&#39;optimizer&#39;: &#39;Adam&#39; # &#39;decay&#39;: {&#39;name&#39;: &#39;cyclic&#39;, &#39;learning_rate&#39;:0.001, # &#39;max_lr&#39;: 0.01, &#39;step_size&#39;: 500}, # &#39;decay&#39;: {&#39;name&#39;: &#39;invtime&#39;, &#39;learning_rate&#39;:0.01, # &#39;decay_steps&#39;: 100, &#39;decay_rate&#39;: 0.05}, # &#39;track&#39;: {&#39;dt&#39;: lambda u, t, e: D(u, t), # &#39;d_epsilon&#39;: lambda u, t, e : D(u, e)} } #sampler = NumpySampler(&#39;uniform&#39;, dim=1, low=0.0, high=30.0) dg = Solver(config) sampler = NumpySampler(&#39;uniform&#39;, dim=1, low=0.0, high=10.0) dg.fit(batch_size=50, sampler=sampler, n_iters=10000) t_reshaped = t[:, None] res = dg.solve(t_reshaped) plt.plot(t, res[:,0], label=&quot;NN Prey&quot;) plt.plot(t, res[:,1], label=&quot;NN Predator&quot;) plt.plot(t, prey, label=&quot;SP Prey&quot;) plt.plot(t, predator, label=&quot;SP Predator&quot;) plt.title(&quot;Predator Error&quot;) plt.legend() # dtm = 5.0 # tms = np.arange(1.0, 30.0+dtm, dtm) # n_iter_per_tm = 10000 # for j, tm in enumerate(tms): # sampler = NumpySampler(&#39;uniform&#39;, dim=1, low=0.0, high=tm) # dg.fit(batch_size=50, sampler=sampler, n_iters=(j+1)*n_iter_per_tm, bar=&#39;notebook&#39;) . &lt;matplotlib.legend.Legend at 0x1e140858c88&gt; . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-08T19:30:50.643472 image/svg+xml Matplotlib v3.4.2, https://matplotlib.org/ plt.plot(res[:,0], res[:,1], label=&quot;NN Prey&quot;) . [&lt;matplotlib.lines.Line2D at 0x1e140a6a208&gt;] . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-08T19:32:29.572355 image/svg+xml Matplotlib v3.4.2, https://matplotlib.org/ sampler = NumpySampler(&#39;uniform&#39;, dim=1, low=0.0, high=4.0) dg.fit(batch_size=50, sampler=sampler, n_iters=10000) t_reshaped = t[:, None] res = dg.solve(t_reshaped) plt.plot(t, res[:,0], label=&quot;NN Prey&quot;) plt.plot(t, res[:,1], label=&quot;NN Predator&quot;) plt.plot(t, prey, label=&quot;SP Prey&quot;) plt.plot(t, predator, label=&quot;SP Predator&quot;) plt.title(&quot;Predator Error&quot;) plt.legend() . &lt;matplotlib.legend.Legend at 0x1a7f7b1f188&gt; . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-08T15:33:03.881860 image/svg+xml Matplotlib v3.4.2, https://matplotlib.org/ sampler = NumpySampler(&#39;uniform&#39;, dim=1, low=0.0, high=6.0) dg.fit(batch_size=50, sampler=sampler, n_iters=10000) t_reshaped = t[:, None] res = dg.solve(t_reshaped) plt.plot(t, res[:,0], label=&quot;NN Prey&quot;) plt.plot(t, res[:,1], label=&quot;NN Predator&quot;) plt.plot(t, prey, label=&quot;SP Prey&quot;) plt.plot(t, predator, label=&quot;SP Predator&quot;) plt.title(&quot;Predator Error&quot;) plt.legend() . &lt;matplotlib.legend.Legend at 0x1a78537cec8&gt; . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-08T15:33:20.243434 image/svg+xml Matplotlib v3.4.2, https://matplotlib.org/ sampler = NumpySampler(&#39;uniform&#39;, dim=1, low=0.0, high=8.0) dg.fit(batch_size=50, sampler=sampler, n_iters=10000) t_reshaped = t[:, None] res = dg.solve(t_reshaped) plt.plot(t, res[:,0], label=&quot;NN Prey&quot;) plt.plot(t, res[:,1], label=&quot;NN Predator&quot;) plt.plot(t, prey, label=&quot;SP Prey&quot;) plt.plot(t, predator, label=&quot;SP Predator&quot;) plt.title(&quot;Predator Error&quot;) plt.legend() . &lt;matplotlib.legend.Legend at 0x1a784a6e308&gt; . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-08T15:34:55.041440 image/svg+xml Matplotlib v3.4.2, https://matplotlib.org/ sampler = NumpySampler(&#39;uniform&#39;, dim=1, low=0.0, high=8.0) dg.fit(batch_size=50, sampler=sampler, n_iters=10000) t_reshaped = t[:, None] res = dg.solve(t_reshaped) plt.plot(t, res[:,0], label=&quot;NN Prey&quot;) plt.plot(t, res[:,1], label=&quot;NN Predator&quot;) plt.plot(t, prey, label=&quot;SP Prey&quot;) plt.plot(t, predator, label=&quot;SP Predator&quot;) plt.title(&quot;Predator Error&quot;) plt.legend() . &lt;matplotlib.legend.Legend at 0x1a7fbc765c8&gt; . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-08T15:35:23.784386 image/svg+xml Matplotlib v3.4.2, https://matplotlib.org/ sampler = NumpySampler(&#39;uniform&#39;, dim=1, low=0.0, high=8.0) dg.fit(batch_size=50, sampler=sampler, n_iters=10000) t_reshaped = t[:, None] res = dg.solve(t_reshaped) plt.plot(t, res[:,0], label=&quot;NN Prey&quot;) plt.plot(t, res[:,1], label=&quot;NN Predator&quot;) plt.plot(t, prey, label=&quot;SP Prey&quot;) plt.plot(t, predator, label=&quot;SP Predator&quot;) plt.title(&quot;Predator Error&quot;) plt.legend() . &lt;matplotlib.legend.Legend at 0x1a7fae9c2c8&gt; . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-08T15:36:33.226069 image/svg+xml Matplotlib v3.4.2, https://matplotlib.org/ sampler = NumpySampler(&#39;uniform&#39;, dim=1, low=0.0, high=10.0) dg.fit(batch_size=50, sampler=sampler, n_iters=10000) t_reshaped = t[:, None] res = dg.solve(t_reshaped) plt.plot(t, res[:,0], label=&quot;NN Prey&quot;) plt.plot(t, res[:,1], label=&quot;NN Predator&quot;) plt.plot(t, prey, label=&quot;SP Prey&quot;) plt.plot(t, predator, label=&quot;SP Predator&quot;) plt.title(&quot;Predator Error&quot;) plt.legend() . &lt;matplotlib.legend.Legend at 0x1a7f2029488&gt; . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-08T15:36:49.302126 image/svg+xml Matplotlib v3.4.2, https://matplotlib.org/ sampler = NumpySampler(&#39;uniform&#39;, dim=1, low=0.0, high=10.0) dg.fit(batch_size=50, sampler=sampler, n_iters=10000) t_reshaped = t[:, None] res = dg.solve(t_reshaped) plt.plot(t, res[:,0], label=&quot;NN Prey&quot;) plt.plot(t, res[:,1], label=&quot;NN Predator&quot;) plt.plot(t, prey, label=&quot;SP Prey&quot;) plt.plot(t, predator, label=&quot;SP Predator&quot;) plt.title(&quot;Predator Error&quot;) plt.legend() . &lt;matplotlib.legend.Legend at 0x1a785363608&gt; . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-08T15:37:54.015064 image/svg+xml Matplotlib v3.4.2, https://matplotlib.org/ sampler = NumpySampler(&#39;uniform&#39;, dim=1, low=0.0, high=10.0) dg.fit(batch_size=50, sampler=sampler, n_iters=10000) t_reshaped = t[:, None] res = dg.solve(t_reshaped) plt.plot(t, res[:,0], label=&quot;NN Prey&quot;) plt.plot(t, res[:,1], label=&quot;NN Predator&quot;) plt.plot(t, prey, label=&quot;SP Prey&quot;) plt.plot(t, predator, label=&quot;SP Predator&quot;) plt.title(&quot;Predator Error&quot;) plt.legend() . &lt;matplotlib.legend.Legend at 0x1a7f57086c8&gt; . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-08T15:40:04.405164 image/svg+xml Matplotlib v3.4.2, https://matplotlib.org/ sampler = NumpySampler(&#39;uniform&#39;, dim=1, low=0.0, high=14.0) dg.fit(batch_size=50, sampler=sampler, n_iters=10000) t_reshaped = t[:, None] res = dg.solve(t_reshaped) plt.plot(t, res[:,0], label=&quot;NN Prey&quot;) plt.plot(t, res[:,1], label=&quot;NN Predator&quot;) plt.plot(t, prey, label=&quot;SP Prey&quot;) plt.plot(t, predator, label=&quot;SP Predator&quot;) plt.title(&quot;Predator Error&quot;) plt.legend() . &lt;matplotlib.legend.Legend at 0x1a7ec3cdb48&gt; . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-08T16:01:59.272580 image/svg+xml Matplotlib v3.4.2, https://matplotlib.org/ plt.plot(res[:,0], res[:,1], label=&quot;NN Prey&quot;) plt.show() . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-08T15:41:24.583617 image/svg+xml Matplotlib v3.4.2, https://matplotlib.org/ It looks like that did something exciting! Let&#39;s look at how our loss function evolved as the network was trained. . n_iters = len(dg.loss) it_idx = [i+1 for i in range(n_iters)] fig, axs = plt.subplots(1, 2, figsize=(13,5)) axs[0].plot(it_idx, dg.loss) axs[0].set_ylabel(&#39;Loss&#39;) axs[0].set_xlabel(&#39;Iteration&#39;) axs[1].plot(it_idx, dg.loss) axs[1].set_ylabel(&#39;Log Loss&#39;) axs[1].set_xlabel(&#39;Iteration&#39;) axs[1].set_yscale(&#39;log&#39;) plt.show() . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-08T15:38:27.719634 image/svg+xml Matplotlib v3.4.2, https://matplotlib.org/ plot_loss(dg.loss) . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-08T13:32:05.918283 image/svg+xml Matplotlib v3.4.2, https://matplotlib.org/ Now that we have our trained neural network, let&#39;s compare its estimated solution with the solution we got earlier from scipy.integrate.odeint. . t_reshaped = t[:, None] res = dg.solve(t_reshaped) plt.plot(t, res[:,0], label=&quot;NN Prey&quot;) plt.plot(t, res[:,1], label=&quot;NN Predator&quot;) plt.plot(t, prey, label=&quot;SP Prey&quot;) plt.plot(t, predator, label=&quot;SP Predator&quot;) plt.title(&quot;Predator Error&quot;) plt.legend() . &lt;matplotlib.legend.Legend at 0x1a7f488ea88&gt; . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-08T13:33:21.170666 image/svg+xml Matplotlib v3.4.2, https://matplotlib.org/ t_reshaped = t[:, None] res = dg.solve(t_reshaped) plt.plot(t, np.abs(prey - res[:,0]), label=&quot;Prey Error&quot;) plt.plot(t, np.abs(predator - res[:,1]), label=&quot;Predator Error&quot;) plt.title(&quot;Error&quot;) plt.legend() plt.show() . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-08T13:36:07.651416 image/svg+xml Matplotlib v3.4.2, https://matplotlib.org/ def check_if_stable(loss, lookback_its = ): &quot;&quot;&quot;Checks if the loss curve has flattened out. &quot;&quot;&quot; . np.mean(np.diff(dg.loss)) . -0.0008927509 . Now suppose that the observed data we see in reality is some sparsely-observed subset of this data, contaminated by some Gaussian noise with mean zero and variance $ sigma^2_{ text{true}} = 100.0$. Let&#39;s take a subset of the points from above and add on this noise. . t_idxs = np.arange(0, 1000, 50) t_obs = t[t_idxs] prey_obs, predator_obs = sol[t_idxs, :].T # Add on noise sigma_true = 10.0 prey_obs += sigma_true*np.random.randn(len(prey_obs)) predator_obs += sigma_true*np.random.randn(len(predator_obs)) . fig, axs = plt.subplots(figsize=(13,5)) axs.plot(t, prey, label=&quot;True Prey&quot;) axs.plot(t, predator, label=&quot;True Predator&quot;) axs.scatter(t_obs, prey_obs, label=&quot;Observed Prey&quot;) axs.scatter(t_obs, predator_obs, label=&quot;Observed Predator&quot;) axs.set_xlabel(&quot;Time&quot;) axs.set_ylabel(&quot;Population&quot;) axs.set_title(&quot;Lotka-Volterra Model&quot;) axs.legend() plt.show() . . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2021-07-07T21:33:03.526145 image/svg+xml Matplotlib v3.4.2, https://matplotlib.org/ Some sources . http://mattpitkin.github.io/samplers-demo/pages/pymc3-blackbox-likelihood/ .",
            "url": "https://jlindbloom.github.io/qed404/2021/01/01/ode-inference-with-pydens-and-pymc3.html",
            "relUrl": "/2021/01/01/ode-inference-with-pydens-and-pymc3.html",
            "date": " • Jan 1, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "I am an incoming first-year applied mathematics PhD student at Dartmouth College, originally from Dallas. I like learning about computational methods for solving (inverse) problems and quantifying uncertainty. Open-source + science is pretty neat too, so sometimes I write about this here. . . I can be reached by email at jonathan@lindbloom.com. . This website is powered by fastpages and .",
          "url": "https://jlindbloom.github.io/qed404/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://jlindbloom.github.io/qed404/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}